{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16826c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anytree in /home/besginow/anaconda3/envs/sage/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/besginow/anaconda3/envs/sage/lib/python3.10/site-packages (from anytree) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install anytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c252e947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pprint\n",
    "from anytree import Node, RenderTree\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tikzplotlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dca837a3",
   "metadata": {},
   "source": [
    "For future iterations of this I might change the scheme to a deep directory based approach.    \n",
    "Then iterations would be named `1.pickle`, `2.pickle` and be stored in deep directories like:    \n",
    "`\"Experiment_name/config1/config2/config3/config4/1.pickle\"`    \n",
    "This way I could just split the name accross the folder separator and have all the setting values, then the only thing I need is a list that gives me the correct setting-value assignment, which sounds a lot easier."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afa87acf",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bb3e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(filepath : str):\n",
    "    file_object = open(filepath, \"rb\")\n",
    "    results = pickle.load(file_object)\n",
    "    file_object.close()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9256daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_setting_from_name(name :str, naming_schema : list):\n",
    "    result = {}\n",
    "    # Main assumption for the naming schema: parameters are strictly separated by underscores '_'\n",
    "    for value, setting in zip(name.split(\"_\"), naming_schema):\n",
    "        result[setting] = value\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "02415768",
   "metadata": {},
   "source": [
    "class Tree:\n",
    "    def __init__(self, leaves : list, parent=None):\n",
    "        self.parent = parent\n",
    "        self.leaves = leaves\n",
    "\n",
    "        \n",
    "    def recursive_tree_print(self, root):\n",
    "        line = \"\"\n",
    "        for branch in root:\n",
    "            if type(branch) == Tree:\n",
    "                line += f\"{branch} -\"\n",
    "                line += self.recursive_tree_print(branch)\n",
    "            elif type(branch) == list:\n",
    "                for b in branch:\n",
    "                    line += b + \"\\t\"\n",
    "            else:\n",
    "                line += branch + \"\\t\"\n",
    "        return line\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.recursive_tree_print(self.leaves)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ab46d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(directory, experiment_name, naming_schema=None, regex_scheme=None):\n",
    "    path = Path(directory)\n",
    "\n",
    "    dirs = [e for e in path.iterdir() if e.is_dir() and not str(e) == '.ipynb_checkpoints']\n",
    "    subdirs = {str(path): [e for e in path.iterdir() if e.is_dir()] for path in dirs}\n",
    "    \n",
    "    relevant_subdirs = subdirs[os.path.join(directory, experiment_name)]\n",
    "    relevant_subdirs.sort()\n",
    "    #result_filename = '*.pickle'\n",
    "    pickle_dirs = list()\n",
    "    for subdir in relevant_subdirs:\n",
    "        if regex_scheme:\n",
    "            pickle_dirs.extend(sorted(subdir.glob(regex_scheme)))\n",
    "        else:\n",
    "            pickle_dirs.extend(sorted(subdir.glob(\"*.pickle\")))\n",
    "    results = []\n",
    "    if not naming_schema is None:\n",
    "        all_attributes = [extract_setting_from_name(subdir.name, naming_schema) for subdir in relevant_subdirs]    \n",
    "        for attributes, pick in zip(all_attributes, pickle_dirs):\n",
    "            try:\n",
    "                unpickled_stuff = unpickle(pick)\n",
    "                results.append({'attributes': attributes, 'results': unpickled_stuff})\n",
    "            except:\n",
    "                # Sometimes there were unknown issues with the pickle files, in those instances we re-ran training\n",
    "                print(\"Catastrophic failure\")\n",
    "    else:\n",
    "        for pick in pickle_dirs:\n",
    "            try:\n",
    "                unpickled_stuff = unpickle(pick)\n",
    "                results.append({'results': unpickled_stuff})\n",
    "            except:\n",
    "                # Sometimes there were unknown issues with the pickle files, in those instances we re-ran training\n",
    "                print(\"Catastrophic failure\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef7376c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_dict_get(data : dict, path : str):\n",
    "    \"\"\"\n",
    "    path a slash ('/') separated path down to \n",
    "    \"\"\"\n",
    "    temp = data.copy()\n",
    "    for entry in path.split(\"/\"):\n",
    "        # Catches leading '/' in tree printing\n",
    "        if entry == '':\n",
    "            continue\n",
    "        temp = temp[entry]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f41bc6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_values(d1 : dict, d2 : dict, path : str):\n",
    "    v1 = deep_dict_get(d1, path)\n",
    "    v2 = deep_dict_get(d2, path)\n",
    "    # Sanity check 1\n",
    "    if not type(v1) == type(v2):\n",
    "        return False\n",
    "    else:\n",
    "        # This can potentially cause errors when comparing lists of lists (or Tensors/Arrays)\n",
    "        return v1 == v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d833486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_common_root_list(root : str, values : list):\n",
    "    return [f\"{root}/{val}\" for val in values]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ed03ddf",
   "metadata": {},
   "source": [
    "# Main functions    \n",
    "What features do I need?    \n",
    "- ~~Show a structure tree of the results (i.e. experiment settings and result values)~~~\n",
    "- ~~Filtering by setting, given a key~~\n",
    "- ~~Filtering by values, given a key~~\n",
    "- Create selected statistics (mean/med/std/quartiles/...) for certain values/keys\n",
    "- Apply a function to certain values/keys and return the results (e.g. Eigendecomposition/Normalization/...)\n",
    "- ~~Group all entries that share settings/values~~\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb4593bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tree_structure(data, parent=None):\n",
    "    # Solved through recursively going deeper into the data structure and then returning the leafs if at the end\n",
    "\n",
    "    if parent is None and not len(data.keys()) == 1:\n",
    "        parent = Node(\"root\")\n",
    "    elif parent is None:\n",
    "        parent = Node(list(data.keys())[0])\n",
    "        data = data[list(data.keys())[0]]\n",
    "    \n",
    "    # Recursion condition\n",
    "    # If there are any dictionaries inside then go deeper\n",
    "    if not any([type(data[entry]) == dict for entry in data]):\n",
    "        for entry in data:\n",
    "            Node(entry, parent=parent) \n",
    "    else:\n",
    "        for entry in data:\n",
    "            if type(data[entry]) == dict:\n",
    "                branch = Node(entry, parent=parent)\n",
    "                generate_tree_structure(data[entry], parent=branch)\n",
    "            else:\n",
    "                Node(entry, parent=parent)\n",
    "    return parent\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da64394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by(list_of_data : list, path, value=None):\n",
    "    \"\"\"\n",
    "    value : If None, make subgroups of equal values. \n",
    "            Otherwise return a single group where value is matched\n",
    "    \"\"\"\n",
    "    grouped_data = {}\n",
    "\n",
    "    if not value is None:\n",
    "        grouped_data[f\"{path} = {value}\"] = [data for data in list_of_data if deep_dict_get(data, path) == value]\n",
    "    else:    \n",
    "        finished_values = list()\n",
    "        for data in list_of_data:\n",
    "            value = deep_dict_get(data, path)\n",
    "            if f\"{path} = {value}\" in grouped_data.keys():\n",
    "                grouped_data[f\"{path} = {value}\"].append(data)\n",
    "            else:\n",
    "                grouped_data[f\"{path} = {value}\"] = list()\n",
    "                grouped_data[f\"{path} = {value}\"].append(data)\n",
    "            #if not value in finished_values:\n",
    "            #    grouped_data[f\"{path} = value\"] = [data for data in list_of_data if deep_dict_get(data, path) == value]\n",
    "            #    finished_values.append(value)\n",
    "    return grouped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e29e1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_compare(d1, d2):\n",
    "    # Checking for empty list in d2, i.e. initial value\n",
    "    if not type(d1) == type(d2):\n",
    "        return False\n",
    "    return all((d1.get(k) == v for k, v in d2.items()))\n",
    "        \n",
    "\n",
    "# Could contain an alternative head as (list_of_data : list, paths : [list, dict], values : None) \n",
    "# where paths-values would require a 1-to-1 correspondence. \n",
    "# But this could quickly become error prone on the user side...\n",
    "def group_by_multiple(list_of_data : list, paths):\n",
    "    grouped_data = {}\n",
    "    # Grouping without values\n",
    "    if type(paths) == list:\n",
    "        finished_values = list()\n",
    "        for data in list_of_data:\n",
    "            paths_vals = {path : deep_dict_get(data, path) for path in paths}\n",
    "            # not any X <=> all not X\n",
    "            # i.e. only succeeds when this combination didn't exist before\n",
    "            if not any([dict_comapare(paths_vals, fin_val) for fin_val in finished_values]):\n",
    "                grouped_data[\" ; \".join([f\"{path} = {paths_vals[path]}\" for path in paths_vals])] = [data]\n",
    "            else:\n",
    "                grouped_data[\" ; \".join([f\"{path} = {paths_vals[path]}\" for path in paths_vals])].append(data)\n",
    "\n",
    "    # Grouping by path-value combinations\n",
    "    # Only returns the group where all those pairs are true\n",
    "    elif type(paths) == dict:\n",
    "        # The keys will contain the paths\n",
    "        # The values will be the corresponding expected values\n",
    "        # Yes, this could be a one-liner with a very neat nested list creation, \n",
    "        #  but I chose readability with temporary variables over it.\n",
    "        good_data = list()\n",
    "        for data in list_of_data:\n",
    "            if all([deep_dict_get(data, path) == paths[path] for path in paths]):\n",
    "                good_data.append(data)\n",
    "        grouped_data[\" ; \".join([f\"{path} = {paths[path]}\" for path in paths])] = good_data\n",
    "    return grouped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e065d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by(list_of_data : list, path : str, value):\n",
    "    filtered_data = list()\n",
    "    for data in list_of_data:\n",
    "        if deep_dict_get(data, path) == value:\n",
    "            filtered_data.append(data)\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "174730a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_value(list_of_data : list, path : str):\n",
    "    \"\"\"\n",
    "        returns a list of the target value from each data dict\n",
    "    \"\"\"\n",
    "    list_of_values = list()\n",
    "    for data in list_of_data:\n",
    "        list_of_values.append(deep_dict_get(data, path))\n",
    "    return list_of_values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d505fea3",
   "metadata": {},
   "source": [
    "# Pseudocode blocks\n",
    "\n",
    "\n",
    "def calc_mean(data):\n",
    "    return mean(data)\n",
    "\n",
    "def calc_std(data):\n",
    "    return std(data)\n",
    "\n",
    "\n",
    "def calc_statistics(data, statistics):\n",
    "    if type(statistics) == list:\n",
    "        result dictionary\n",
    "        for statistic in statistics:\n",
    "            result_dict[statistic] = call statistic\n",
    "        return result_dict\n",
    "    else:\n",
    "        reutrn call statistic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b944501",
   "metadata": {},
   "source": [
    "# Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b730f878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#naming_schema = [\"Metric\", \"Kernel_search\", \"train_data_ratio\", \"Data_kernel\", \"weights\", \"Variance_list\", \"eval_START\", \"eval_END\", \"eval_COUNT\", \"optimizer\", \"train_iterations\", \"LR\", \"Noise\", \"Data_scaling\", \"BFGS\"]\n",
    "#all_results = load_results('results', \"hardcoded\", regex_scheme=\"other_datasizes.pickle\")\n",
    "#all_results = load_results('results', \"hardcoded\", regex_scheme=\"LapCor00.pickle\")\n",
    "#all_results = load_results('results', \"hardcoded\", regex_scheme=\"LapCorBIC.pickle\")\n",
    "#all_results = load_results('results', \"hardcoded\", regex_scheme=\"LLapCor00.pickle\")\n",
    "all_results = load_results('results', \"hardcoded\", regex_scheme=\"LLapCorBIC.pickle\")\n",
    "\n",
    "postfix = \"_BIC\"\n",
    "#pprint.pprint(all_results)\n",
    "result_tree = generate_tree_structure(all_results[0]).descendants\n",
    "#pprint.pprint(result_tree)\n",
    "\n",
    "\n",
    "# data - kernel assignment : RBF_PER = SIN*RBF; 4PER = 4C*SIN; PER = C*SIN\n",
    "# Perform for each main dictionary: Iterate over kernels -> Look for the lowest(highest?) loss, \n",
    "\n",
    "\"\"\"\n",
    "for main_dict in all_results:\n",
    "    print(\"############################\")\n",
    "    print(main_dict[\"results\"][\"attributes\"][\"data_gen\"])\n",
    "    for model_kernel in ['C*C*RBF','C*RBF','C*SIN','C*SIN + C*SIN','C*SIN + C*SIN + C*SIN','SIN*RBF']:\n",
    "        print(\"\\n----\")\n",
    "        print(f\"{model_kernel}:\\n\")\n",
    "        for metric in [\"Laplace\", \"MC\", \"MLL\", \"AIC\"]:\n",
    "            print(f\"{metric}\\t - \\t{main_dict['results'][metric][model_kernel]['loss']}\")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# What do I want to know?\n",
    "# 1.) Does each metric recognize the correct kernels?\n",
    "# 1.1.) If not: Why?\n",
    "# 2.) Is the order I was talking about true?\n",
    "# 2.1.) i.e. MLL > Laplace/AIC >=? MCMC\n",
    "# 3.) Are models with redundant parameters more punished than others? Especially the 2SIN vs 3SIN case\n",
    "# 4.) Make a ranking sheet per dataset where the models are compared _within_ a metric to see if there are similarities visible or something\n",
    "#  \n",
    "data_kernels = [\"SE\", \"MAT32\",\"MAT32+SE\", \"MAT32*SE\"]#, \"PER*SE\", \"MAT32+PER\"] # \"PER\",\n",
    "#data_kernels = [\"SE\", \"PER\", \"MAT32\", \"PER*SE\", \"PER+SE\", \"MAT32*PER\", \"MAT32+PER\", \"MAT32+SE\", \"MAT32*SE\"]\n",
    "model_kernels = [ \"SE\", \"MAT32\", \"MAT32+SE\", \"MAT32*SE\", \"C*C*SE\"] # \"PER\", \n",
    "#model_kernels = [\"SE\", \"PER\", \"MAT32\", \"PER*SE\", \"PER+SE\", \"MAT32*PER\", \"MAT32+PER\", \"MAT32+SE\", \"MAT32*SE\", \"C*C*SE\"]\n",
    "#metrics = [\"MC\", \"AIC\", \"BIC\", \"Laplace\", \"Laplace_prior\"]# \"MLL\", \"MAP\"\n",
    "metrics = [\"Laplace\"]# \"MLL\",\n",
    "#metrics = [\"Laplace_prior\"]# \"MLL\",\n",
    "dataset_sizes = [10, 20, 50, 70, 100, 150, 200]\n",
    "data_model_zip = zip(data_kernels, model_kernels[:-1])\n",
    "\n",
    "print(\"1.) Does each metric recognize the correct kernel?\")\n",
    "# 1.) Does each metric recognize the correct kernel?\n",
    "# Iterate over all datasets\n",
    "results_table = {datasize: {f\"{metric}{postfix}\":{\"RR\": list(), \"RR3\":list(), \"runtime\": -1} for metric in metrics} for datasize in dataset_sizes} \n",
    "#for main_dict in all_results:\n",
    "# Iterate over all kernels I tried\n",
    "#for model_kernel in ['C*C*RBF','C*RBF','C*SIN','C*SIN + C*SIN','C*SIN + C*SIN + C*SIN','SIN*RBF']:\n",
    "#print(main_dict[\"results\"][\"attributes\"][\"data_gen\"])\n",
    "for data_num in dataset_sizes:\n",
    "    # Filter for dataset size\n",
    "    data_500 = group_by_multiple(all_results, {'/results/attributes/eval_COUNT': data_num})\n",
    "    data_500_key = list(data_500.keys())[0]\n",
    "\n",
    "    for result in data_500[data_500_key]:\n",
    "        if not deep_dict_get(result, \"results/attributes/data_gen\") in data_kernels:\n",
    "            continue\n",
    "        for metric in metrics:\n",
    "            if result[\"results\"][\"attributes\"][\"data_gen\"] == max([(result['results'][metric][model_kernel]['loss'], model_kernel) for model_kernel in model_kernels])[-1]:\n",
    "                results_table[data_num][f\"{metric}{postfix}\"][\"RR\"].append(True)\n",
    "            else:\n",
    "                results_table[data_num][f\"{metric}{postfix}\"][\"RR\"].append(False)\n",
    "            sorted_results = sorted([(result['results'][metric][model_kernel]['loss'], model_kernel) for model_kernel in model_kernels], key=lambda x:x[0], reverse=True)\n",
    "            top3 = sorted_results[:3]#sorted([(result['results'][metric][model_kernel]['loss'], model_kernel) for model_kernel in model_kernels])[:3]\n",
    "            if result[\"results\"][\"attributes\"][\"data_gen\"] in [t[1] for t in top3]:\n",
    "                results_table[data_num][f\"{metric}{postfix}\"][\"RR3\"].append(True)\n",
    "            else:\n",
    "                results_table[data_num][f\"{metric}{postfix}\"][\"RR3\"].append(False)\n",
    "    #print(f\"{metric}\\t {max([(main_dict['results'][metric][model_kernel]['loss'], model_kernel) for model_kernel in model_kernels])}\")\n",
    "\n",
    "print(\"===============================\")\n",
    "print(\"2.) Is the order I was talking about true? i.e. what is the order or the values for MLL, AIC, Laplace and where does MC lie at?\")\n",
    "# 2.) Is the order I was talking about true? i.e. what is the order or the values for MLL, AIC, Laplace and where does MC lie at?\n",
    "#     It should be ordered AIC > MLL > Laplace\n",
    "#     And somewhere in between there should be MC\n",
    "# Iterate over all datasets\n",
    "for main_dict in all_results:\n",
    "    print(main_dict[\"results\"][\"attributes\"][\"data_gen\"])\n",
    "    # Do this comparison for each model kernel\n",
    "    #[\"SE\", \"PER\", \"MAT32\", \"PER*SE\", \"PER+SE\", \"MAT32*PER\", \"MAT32+PER\", \"MAT32+SE\", \"MAT32*SE\"]\n",
    "    for model_kernel in model_kernels:\n",
    "        ranking = [(main_dict['results'][metric][model_kernel]['loss'], metric) for metric in metrics]\n",
    "        ranking = sorted(ranking, key=lambda x:x[0], reverse=True)\n",
    "        # Check if it either is MLL > Laplace > AIC (this happens if MLL is negative) OR AIC > MLL > Laplace \n",
    "        #if not (main_dict['results'][\"MLL\"][model_kernel]['loss'] > main_dict['results'][\"Laplace\"][model_kernel]['loss'] > main_dict['results'][\"AIC\"][model_kernel]['loss']) and not (main_dict['results'][\"AIC\"][model_kernel]['loss'] > main_dict['results'][\"MLL\"][model_kernel]['loss'] > main_dict['results'][\"Laplace\"][model_kernel]['loss']) :\n",
    "        print(f\"{model_kernel}\\t {ranking}\")\n",
    "\n",
    "#print(\"===============================\")\n",
    "#print(\"3.) Are models with redundant parameters more punished than others? Especially the 2SIN vs 3SIN case\")\n",
    "## 3.) Are models with redundant parameters more punished than others? Especially the 2SIN vs 3SIN case \n",
    "#\n",
    "## Iterate over all datasets\n",
    "#for main_dict in all_results:\n",
    "#    for metric in [\"Laplace\", \"AIC\", \"Laplace_prior\"]:\n",
    "#        print(metric)\n",
    "#        for pair in data_model_zip:#[('C*RBF', 'C*C*RBF'), ('C*SIN', 'C*SIN + C*SIN + C*SIN'), ('C*SIN + C*SIN', 'C*SIN + C*SIN + C*SIN'), ('C*SIN', 'C*SIN + C*SIN')]:\n",
    "#            met_1 = main_dict['results'][metric][pair[0]]['loss'] \n",
    "#            met_2 = main_dict['results'][metric][pair[1]]['loss'] \n",
    "#            if not met_1 > met_2:\n",
    "#                print(f\"{main_dict['results']['attributes']['data_gen']} \\t - {pair}\")\n",
    "        \n",
    "\n",
    "print(\"===============================\")\n",
    "print(\"4.) Make a ranking per dataset how each model kernel was rated\")\n",
    "\n",
    "# 4.) Make a ranking per dataset how each model kernel was rated \n",
    "# Iterate over all datasets\n",
    "confusion_matrix_data = {datasize: {f\"{metric}{postfix}\":{data_kernel : None for data_kernel in data_kernels} for metric in metrics} for datasize in dataset_sizes} \n",
    "for data_num in dataset_sizes:\n",
    "    print(data_num)\n",
    "    # Filter for dataset size\n",
    "    data_500 = group_by_multiple(all_results, {'/results/attributes/eval_COUNT': data_num})\n",
    "    data_500_key = list(data_500.keys())[0]\n",
    "\n",
    "    for result in data_500[data_500_key]:\n",
    "        print(result[\"results\"][\"attributes\"][\"data_gen\"])\n",
    "        for metric in metrics:\n",
    "        # Do this ranking for each metric \n",
    "            print(metric)\n",
    "            ranking = [(result['results'][metric][model_kernel]['loss'], model_kernel) for model_kernel in model_kernels] \n",
    "            key_fkt = lambda x: x[0]\n",
    "            pprint.pprint(sorted(ranking, key=key_fkt, reverse=True))\n",
    "\n",
    "            def div2(input, doit):\n",
    "                if doit:\n",
    "                    return input/2\n",
    "                else:\n",
    "                    return input\n",
    "\n",
    "            confusion_matrix_data[data_num][f\"{metric}{postfix}\"][result[\"results\"][\"attributes\"][\"data_gen\"]] = [div2(result['results'][metric][model_kernel]['loss'].item(), metric in [\"AIC\", \"BIC\"]) for model_kernel in model_kernels]\n",
    "            print(\"===============\")\n",
    "\n",
    "print(\"===============================\")\n",
    "print(\"5.) Runtime of each metric\")\n",
    "\n",
    "# Do this ranking for each metric \n",
    "for data_num in dataset_sizes:\n",
    "    # Filter for dataset size\n",
    "    data_500 = group_by_multiple(all_results, {'/results/attributes/eval_COUNT': data_num})\n",
    "    data_500_key = list(data_500.keys())[0]\n",
    "\n",
    "    for result in data_500[data_500_key]:\n",
    "        for metric in metrics:\n",
    "            #print(metric)\n",
    "            if metric in [\"Laplace\", \"Laplace_prior\", \"BIC\"]:\n",
    "                runtime_list = [result['results'][metric][model_kernel]['details']['Total time'] + result['results'][metric][model_kernel]['Train time']  for model_kernel in model_kernels]\n",
    "            elif metric in [\"MLL\", \"MAP\"]:\n",
    "                runtime_list = [result['results'][metric][model_kernel]['Train time']  for model_kernel in model_kernels]\n",
    "            else:\n",
    "                runtime_list = [result['results'][metric][model_kernel]['details']['Total time'] for model_kernel in model_kernels] \n",
    "            results_table[data_num][metric][\"runtime\"] = np.average(runtime_list)\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9c261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\" & \".join([\"MC\", \"AIC\", \"BIC\", \"Laplace\", \"Laplace_prior\"]))\n",
    "print(\" & \".join(list(all_the_results_tables[data_num].keys())))\n",
    "for data_num in all_the_results_tables:\n",
    "    result_line = f\"\\\\multirow{{3}}{{*}}{{{data_num}}} & \"\n",
    "    for criterium in [\"RR\", \"RR3\", \"runtime\"]:\n",
    "        result_line += f\"{criterium}\"\n",
    "        for metric in all_the_results_tables[data_num]:\n",
    "            if criterium in [\"RR\", \"RR3\"]:\n",
    "                result_line += f\" & {np.round(100*np.count_nonzero(all_the_results_tables[data_num][metric][criterium])/len(all_the_results_tables[data_num][metric][criterium]), 2)}\"\n",
    "            else:\n",
    "                result_line += f\" & {np.round(all_the_results_tables[data_num][metric][criterium], 2)}\"\n",
    "        result_line += \"\\\\\\\\\"\n",
    "        print(result_line)\n",
    "        result_line = \" & \"\n",
    "    print(\"\\\\midrule\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d216570e",
   "metadata": {},
   "source": [
    "fig, axs = plt.subplots(len(dataset_sizes), len(metrics), sharey=True)\n",
    "#fig, axs = plt.subplots(1, len(metrics), sharey=True)\n",
    "for row, data_num in enumerate(dataset_sizes):#enumerate(confusion_matrix_data):\n",
    "    for col, metric in enumerate(confusion_matrix_data[data_num]):\n",
    "        single_conf_matr_data = [confusion_matrix_data[data_num][metric][data_kernel] for data_kernel in data_kernels]\n",
    "        axs[col].matshow(single_conf_matr_data, cmap=plt.cm.GnBu)\n",
    "        fig.colorbar(axs[col].matshow(single_conf_matr_data), cmap=plt.cm.GnBu)\n",
    "        if row == 0:\n",
    "            axs[col].set_xticks(range(len(model_kernels)))\n",
    "            axs[col].set_xticklabels(model_kernels, rotation=90)\n",
    "            axs[col].set_title(metric)\n",
    "        else:\n",
    "            axs[col].set_xticks([])\n",
    "        axs[col].set_yticks(range(len(data_kernels)))\n",
    "        if col == 0:\n",
    "            axs[col].set_ylabel(data_num)\n",
    "        axs[col].set_yticklabels(data_kernels)\n",
    "        \n",
    "fig.set_figwidth(18)\n",
    "fig.set_figheight(1.5)\n",
    "#plt.legend()\n",
    "\n",
    "tikzplotlib.save(\"evaluation/confusion_matrix/confusionMatrix100.tex\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07198f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_the_results_tables = copy.deepcopy(results_table)\n",
    "#all_the_results_tables_bak = copy.deepcopy(all_the_results_tables)\n",
    "all_the_results_tables = {data_num: dict(list(all_the_results_tables[data_num].items()) + list(results_table[data_num].items())) for data_num in all_the_results_tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e574e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_results_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e224dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#all_the_confusion_results_bak = copy.deepcopy(all_the_confusion_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802bbfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import copy\n",
    "#all_the_confusion_results = copy.deepcopy(confusion_matrix_data)\n",
    "#all_the_confusion_results = copy.deepcopy(all_the_confusion_results_bak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e7066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_confusion_results = {data_num: dict(list(all_the_confusion_results[data_num].items()) + list(confusion_matrix_data[data_num].items())) for data_num in all_the_confusion_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4553540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_confusion_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eae281",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(dataset_sizes), len(all_the_confusion_results[10]), sharey=True)\n",
    "all_conf_matr_data = list()\n",
    "#fig, axs = plt.subplots(1, 3, sharey=True)\n",
    "for row, data_num in enumerate(dataset_sizes):#enumerate(confusion_matrix_data):\n",
    "    all_conf_matr_data = list()\n",
    "    for col, metric in enumerate(sorted(all_the_confusion_results[data_num])):\n",
    "        all_conf_matr_data.extend([all_the_confusion_results[data_num][metric][data_kernel] for data_kernel in data_kernels])\n",
    "    minmin = np.min(np.array(all_conf_matr_data).flatten())\n",
    "    maxmax = np.max(np.array(all_conf_matr_data).flatten())\n",
    "    for col, metric in enumerate(sorted(all_the_confusion_results[data_num])):\n",
    "        #all_conf_matr_data.extend([all_the_confusion_results[data_num][metric][data_kernel] for data_kernel in data_kernels])\n",
    "        im = axs[row, col].matshow([all_the_confusion_results[data_num][metric][data_kernel] for data_kernel in data_kernels], vmin=minmin, vmax=maxmax)\n",
    "        #fig.colorbar(axs[row, col].matshow(single_conf_matr_data), cmap=plt.cm.GnBu)\n",
    "        if row == 0:\n",
    "            axs[row, col].set_xticks(range(len(model_kernels)))\n",
    "            axs[row, col].set_xticklabels(model_kernels, rotation=90)\n",
    "            axs[row, col].set_title(metric)\n",
    "        else:\n",
    "            axs[row, col].set_xticks([])\n",
    "        axs[row, col].set_yticks(range(len(data_kernels)))\n",
    "        if col == 0:\n",
    "            axs[row, col].set_ylabel(data_num)\n",
    "        axs[row, col].set_yticklabels(data_kernels)\n",
    "    plt.colorbar(im)\n",
    "        \n",
    "\n",
    "#fig.colorbar(np.array(all_conf_matr_data))\n",
    "#plt.colorbar(im)\n",
    "fig.set_figwidth(30)\n",
    "fig.set_figheight(15)\n",
    "#plt.legend()\n",
    "\n",
    "tikzplotlib.save(\"evaluation/confusion_matrix/allConfusionMatrix.tex\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81826762",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2239685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "6660c3d1",
   "metadata": {},
   "source": [
    "#all_results[0][\"results\"][\"attributes\"][\"data_gen\"]\n",
    "pprint.pprint(all_results[0][\"results\"][\"Laplace\"][\"4C*SIN\"][\"details\"])\n",
    "MLL = all_results[0][\"results\"][\"Laplace\"][\"4C*SIN\"][\"details\"][\"MLL\"]\n",
    "H = all_results[0][\"results\"][\"Laplace\"][\"4C*SIN\"][\"details\"][\"corrected Hessian\"]\n",
    "S = torch.diag(all_results[0][\"results\"][\"Laplace\"][\"4C*SIN\"][\"details\"][\"diag(prior var)\"])\n",
    "t_mu = all_results[0][\"results\"][\"Laplace\"][\"4C*SIN\"][\"details\"][\"prior mean\"]\n",
    "t_0 = all_results[0][\"results\"][\"Laplace\"][\"4C*SIN\"][\"details\"][\"parameter values\"]\n",
    "\n",
    "diff = t_mu - t_0\n",
    "mid_term = (S.inverse() - H).inverse()\n",
    "matmuls = diff.t() @ S.inverse() @ mid_term @ H @ diff\n",
    "print(matmuls)\n",
    "#print(torch.log(S.det()))\n",
    "print(MLL - 0.5*torch.log(S.det()) - 0.5*torch.log(mid_term.det()) + 0.5* matmuls)\n",
    "#pprint.pprint(list(zip(all_results[0][\"results\"][\"Laplace\"][\"4C*SIN\"][\"details\"]['parameter list'], all_results[0][\"results\"][\"Laplace\"][\"4C*SIN\"][\"details\"]['parameter values'])))\n",
    "\n",
    "#pprint.pprint(torch.linalg.eig(all_results[0][\"results\"][\"Laplace\"][\"4C*SIN\"][\"details\"][\"corrected Hessian\"]))\n",
    "#pprint.pprint(torch.linalg.eig(all_results[0][\"results\"][\"Laplace\"][\"4C*SIN\"][\"details\"][\"original symmetrized Hessian\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a0451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "metrics = [\"Laplace0.0\", \"Laplace2.0\", \"LaplaceBIC\",  \"AIC\", \"BIC\", \"Laplace_prior0.0\", \"Laplace_prior2.0\", \"Laplace_priorBIC\"]\n",
    "kernel_recognition_dict = {data_num : {metric : {\"1\" : 0, \"2\" : 0} for metric in metrics} for data_num in [5, 10, 20, 30, 40, 50, 70, 100, 150, 200]}\n",
    "for data_num in [5, 10, 20, 30, 40, 50, 70, 100, 150, 200]:#, 100, 250, 500]:\n",
    "    print(\"======================\")\n",
    "    results_dict[data_num] = {}\n",
    "    print(data_num)\n",
    "    # Verify the recognition ratio of \"PER\", \"MAT32\", \"PER*SE\", \"PER+SE\", \"MAT32*PER\", \"MAT32+PER\"\n",
    "    kernel_distributions = {}\n",
    "    for key in [\"Laplace\", \"AIC\", \"BIC\", \"Laplace_prior\"]:#MLL\n",
    "        print(key)\n",
    "        all_results = load_results('results', key)#, regex_scheme=\"[0-29].pickle\")\n",
    "        result_tree = generate_tree_structure(all_results[0]).descendants\n",
    "        #pprint.pprint(result_tree)\n",
    "        #total_runs = len(all_results[0])\n",
    "        #print(all_results[0]['results']['attributes']['Data_kernel'])\n",
    "        #winners = group_by(all_results, 'results/results/final model', value='(c * PER)')['results/results/final model = (c * PER)']\n",
    "        data_kernels = [(\"SE\", \"(c * SE)\"), (\"RQ\", \"(c * RQ)\"), (\"PER\", \"(c * PER)\"), (\"MAT32\", \"(c * MAT32)\"), (\"PER*SE\", \"((c * PER) * (c * SE))\"), (\"PER+SE\", \"((c * PER) + (c * SE))\"), (\"MAT32*PER\", \"((c * MAT32) * (c * PER))\"), (\"MAT32+PER\", \"((c * MAT32) + (c * PER))\"),(\"MAT32+SE\", \"((c * MAT32) + (c * SE))\"),(\"MAT32*SE\", \"((c * MAT32) * (c * SE))\")]\n",
    "        data_500 = group_by_multiple(all_results, {'/results/attributes/eval_COUNT': data_num})\n",
    "        #data_0_punish = group_by(all_results, '/results/attributes/parameter_punishment', 0.0)\n",
    " \n",
    "        kernel_distributions[key] = group_by(data_500[f\"/results/attributes/eval_COUNT = {data_num}\"], '/results/results/final model')\n",
    "        if key in [\"Laplace\", \"Laplace_prior\"]:\n",
    "            data_500 = group_by(data_500[f\"/results/attributes/eval_COUNT = {data_num}\"], '/results/attributes/parameter_punishment')\n",
    "            for punish_key in list(data_500.keys()):\n",
    "                sum_recognized = 0\n",
    "                sum_total = 0\n",
    "                all_results = data_500[punish_key]\n",
    "                for data_kernel, goal_kernel in data_kernels:\n",
    "                    print(f\"Data: {data_kernel}; Punish: {punish_key.split('=')[-1][1:]}\")\n",
    "                    total_runs = group_by(all_results, '/results/attributes/Data_kernel', data_kernel)\n",
    "                    #SE_count = group_by(all_results, '/results/results/final model', \"(c * SE)\")\n",
    "                    #mat32_count = group_by(all_results, '/results/results/final model', \"(c * MAT32)\")\n",
    "                    #mat52_count = group_by(all_results, '/results/results/final model', \"(c * MAT52)\")\n",
    "                    #print(f\"SE count: {len(SE_count[f'/results/results/final model = (c * SE)'])}\")\n",
    "                    #print(f\"MAT32 count: {len(mat32_count[f'/results/results/final model = (c * MAT32)'])}\")\n",
    "                    #print(f\"MAT52 count: {len(mat52_count[f'/results/results/final model = (c * MAT52)'])}\")\n",
    "                    winners = group_by_multiple(all_results, {'/results/attributes/Data_kernel' : data_kernel, 'results/results/final model' : goal_kernel})\n",
    "                    print(f\"Recognized {len(winners[f'/results/attributes/Data_kernel = {data_kernel} ; results/results/final model = {goal_kernel}'])} of {len(total_runs[f'/results/attributes/Data_kernel = {data_kernel}'])}\")\n",
    "                    recognized = len(winners[f'/results/attributes/Data_kernel = {data_kernel} ; results/results/final model = {goal_kernel}'])\n",
    "                    if \"+\" in data_kernel or \"*\" in data_kernel:\n",
    "                        kernel_recognition_dict[data_num][f\"{key}{punish_key.split('=')[-1][1:]}\"][\"2\"] += recognized\n",
    "                    else:\n",
    "                        kernel_recognition_dict[data_num][f\"{key}{punish_key.split('=')[-1][1:]}\"][\"1\"] += recognized\n",
    "                    sum_recognized += recognized\n",
    "                    sum_total += len(total_runs[f'/results/attributes/Data_kernel = {data_kernel}'])\n",
    "                results_dict[data_num][f\"{key}_{punish_key.split('=')[-1][1:]}\"] = {}\n",
    "                results_dict[data_num][f\"{key}_{punish_key.split('=')[-1][1:]}\"][f\"Total\"] = sum_total\n",
    "                results_dict[data_num][f\"{key}_{punish_key.split('=')[-1][1:]}\"][f\"Recognized\"] = sum_recognized \n",
    "                print(f\"{sum_recognized}/{sum_total}\")\n",
    "        else:\n",
    "            results_dict[data_num][key] = {}\n",
    "            sum_recognized = 0\n",
    "            sum_total = 0\n",
    "            all_results = data_500[f\"/results/attributes/eval_COUNT = {data_num}\"]\n",
    "            for data_kernel, goal_kernel in data_kernels:\n",
    "                print(f\"Data: {data_kernel}\")\n",
    "                total_runs = group_by(all_results, '/results/attributes/Data_kernel', data_kernel)\n",
    "                #SE_count = group_by(all_results, '/results/results/final model', \"(c * SE)\")\n",
    "                #mat32_count = group_by(all_results, '/results/results/final model', \"(c * MAT32)\")\n",
    "                #mat52_count = group_by(all_results, '/results/results/final model', \"(c * MAT52)\")\n",
    "                #print(f\"SE count: {len(SE_count[f'/results/results/final model = (c * SE)'])}\")\n",
    "                #print(f\"MAT32 count: {len(mat32_count[f'/results/results/final model = (c * MAT32)'])}\")\n",
    "                #print(f\"MAT52 count: {len(mat52_count[f'/results/results/final model = (c * MAT52)'])}\")\n",
    "                winners = group_by_multiple(all_results, {'/results/attributes/Data_kernel' : data_kernel, 'results/results/final model' : goal_kernel})\n",
    "                print(f\"Recognized {len(winners[f'/results/attributes/Data_kernel = {data_kernel} ; results/results/final model = {goal_kernel}'])} of {len(total_runs[f'/results/attributes/Data_kernel = {data_kernel}'])}\")\n",
    "                recognized = len(winners[f'/results/attributes/Data_kernel = {data_kernel} ; results/results/final model = {goal_kernel}'])\n",
    "                if \"+\" in data_kernel or \"*\" in data_kernel:\n",
    "                    kernel_recognition_dict[data_num][f\"{key}\"][\"2\"] += recognized\n",
    "                else:\n",
    "                    kernel_recognition_dict[data_num][f\"{key}\"][\"1\"] += recognized\n",
    "                sum_recognized += recognized\n",
    "                sum_total += len(total_runs[f'/results/attributes/Data_kernel = {data_kernel}'])\n",
    "            results_dict[data_num][key][f\"Total\"] = sum_total\n",
    "            results_dict[data_num][key][f\"Recognized\"] = sum_recognized \n",
    "            print(f\"{sum_recognized}/{sum_total}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97084ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print([kernel for kernel in [ 'AIC', 'BIC', 'Laplace_2.0' 'Laplace_prior_0.0', 'Laplace_prior_BIC']])\n",
    "print(\" & \".join([k for k in results_dict[5]]))\n",
    "for data_num in results_dict:\n",
    "    #print(f\"RR \\\\@ {data_num} & {' & '.join([str(100*results_dict[data_num][kernel]['Recognized']/results_dict[data_num][kernel]['Total']) for kernel in [  'AIC', 'BIC', 'Laplace_2.0' , 'Laplace_prior_0.0', 'Laplace_prior_BIC']])} \\\\\\\\\")\n",
    "    print(f\"RR \\\\@ {data_num} & {' & '.join([str(100*results_dict[data_num][kernel]['Recognized']/results_dict[data_num][kernel]['Total']) for kernel in results_dict[data_num]])} \\\\\\\\\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a391e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawing_dataset = [list() for i in range(5)]\n",
    "for i, data_num in enumerate(results_dict):\n",
    "    keys = list(results_dict[data_num])\n",
    "    for key in results_dict[data_num]:\n",
    "        drawing_dataset[i].append(results_dict[data_num][key][\"Recognized\"])\n",
    "plt.plot([10, 20, 50], drawing_dataset, marker='o', label=keys)\n",
    "plt.ylabel(\"Recognized kernels\")\n",
    "plt.xlabel(\"Dataset size\")\n",
    "plt.legend(loc=\"upper right\", bbox_to_anchor=(0.4, 0.0, 1, 1))\n",
    "plt.savefig(\"evaluation/Recognized_kernels_per_datasets.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b559da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e42732",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, key in enumerate(kernel_distributions):\n",
    "    fig, axs = plt.subplots(figsize=(15, 3))\n",
    "    label_count = {}\n",
    "    for kernel in sorted(kernel_distributions[key], key=len, reverse=False):\n",
    "        kernel_name = kernel.split(\"=\")[-1][1:]\n",
    "        label_count[kernel_name] = len(kernel_distributions[key][kernel])\n",
    "    axs.bar(range(len(label_count.keys())), label_count.values())\n",
    "    axs.set_title(key)\n",
    "    plt.xticks(range(len(label_count.keys())), label_count.keys(), rotation=\"vertical\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd71d8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  The behaviour of the negative correction subtracted from the MAP resp. MLL values\n",
    "key = \"Laplace\"\n",
    "all_results = load_results('results', key)\n",
    "#result_tree = generate_tree_structure(all_results[0]).descendants\n",
    "all_results = group_by(all_results, '/results/attributes/parameter_punishment')\n",
    "fig, axs = plt.subplots(1, 3, sharey=True)\n",
    "for col, punish_level in enumerate(all_results):\n",
    "    num_replaced_list = list()\n",
    "    punish_term_list = list()\n",
    "    param_num_list = [list() for i in range(0, 11, 1)]\n",
    "    for result in all_results[punish_level]:\n",
    "        details = deep_dict_get(result, \"/results/results/details\")\n",
    "        # iterate over all kernels that were tried in the kernel search\n",
    "        for tried_kernel in details:\n",
    "            param_num_list[tried_kernel[\"num_replaced\"]].append(\n",
    "                tried_kernel[\"punish term\"].item())\n",
    "                #num_replaced_list.append(tried_kernel[\"num_replaced\"])\n",
    "                #punish_term_list.append(tried_kernel[\"punish term\"][0][0])\n",
    "    #axs[col].scatter(num_replaced_list, punish_term_list, marker=\".\")\n",
    "    axs[col].boxplot(param_num_list, positions=range(0, 11, 1), showfliers=False)\n",
    "    axs[col].plot([0,10], [0, 0], color=\"red\", linewidth=0.5)\n",
    "    axs[col].set_title(f\"{punish_level.split('=')[-1]}\")\n",
    "    axs[col].set_xlabel(\"Replaced values\")\n",
    "    if col == 0:\n",
    "        axs[col].set_ylabel(\"Punish term\")\n",
    "fig.set_figwidth(13)\n",
    "fig.set_figheight(3)\n",
    "tikzplotlib.save(f\"evaluation/negative_correction_{key}_boxplot.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e29d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The distribution of replaced parameters over the number of available parameters\n",
    "key = \"Laplace\"\n",
    "all_results = load_results('results', key)\n",
    "#result_tree = generate_tree_structure(all_results[0]).descendants\n",
    "all_results = group_by(all_results, '/results/attributes/parameter_punishment')\n",
    "fig, axs = plt.subplots(1, 3, sharey=True)\n",
    "for col, punish_level in enumerate(all_results):\n",
    "    param_num_list = [list() for i in range(0, 11, 1)]\n",
    "    for result in all_results[punish_level]:\n",
    "        details = deep_dict_get(result, \"/results/results/details\")\n",
    "        # iterate over all kernels that were tried in the kernel search\n",
    "        for tried_kernel in details:\n",
    "            param_num_list[len(tried_kernel[\"parameter list\"])].append(\n",
    "                tried_kernel[\"num_replaced\"])\n",
    "    #axs[col].scatter(num_replaced_list, punish_term_list, marker=\".\")\n",
    "    axs[col].boxplot(param_num_list[3:], positions=range(3, 11, 1), showfliers=False)\n",
    "    #axs[col].plot([0,max(num_replaced_list)], [0, 0], color=\"red\")\n",
    "    axs[col].set_title(f\"{punish_level.split('=')[-1]}\")\n",
    "    axs[col].set_xlabel(\"Num. parameters\")\n",
    "    if col == 0:\n",
    "        axs[col].set_ylabel(\"Num. replaced\")\n",
    "fig.set_figwidth(13)\n",
    "fig.set_figheight(3)\n",
    "tikzplotlib.save(f\"evaluation/replaced_params_{key}.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8d9a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots over the number of parameters that each metric allows over the dataset sizes (i.e. kernel sizes)\n",
    "kernel_distributions = {}\n",
    "keys = [\"MLL\", \"AIC\", \"BIC\", \"Laplace\", \"Laplace_prior\"]\n",
    "for data_num in [10, 50, 100, 250, 500]:\n",
    "    print(data_num)\n",
    "    num_param_list = [list() for i in range(len(keys))] \n",
    "    for i, key in enumerate(keys):\n",
    "        print(key)\n",
    "        all_results = load_results('results', key)\n",
    "        datasize_filtered = group_by_multiple(all_results, {'/results/attributes/eval_COUNT': data_num})\n",
    "        for result in datasize_filtered[list(datasize_filtered.keys())[0]]:\n",
    "            parameters = deep_dict_get(result, \"/results/results/parameters\")\n",
    "            num_param_list[i].append(len(parameters))\n",
    "            # iterate over all kernels that were tried in the kernel search\n",
    "    plt.violinplot(num_param_list)\n",
    "    plt.title(f\"Kernel sizes for {data_num} datapoints\")\n",
    "    plt.xlabel(\"Metric\")\n",
    "    plt.ylabel(\"Kernel size\")\n",
    "    plt.savefig(f\"evaluation/kernel_sizes_{data_num}_violin.png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7acce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "dataset_sizes = [10, 20, 30, 40, 50, 70, 100, 150, 200]\n",
    "kernel_distributions = {}\n",
    "#key = \"Laplace_prior\"\n",
    "#all_results = load_results('results', key)\n",
    "#result_tree = generate_tree_structure(all_results[0]).descendants\n",
    "#avg_additional_punish = list()#[list() for i in range(0, 11, 1)]\n",
    "#param_num_list = list()#[list() for i in range(0, 11, 1)] \n",
    "#punish_without_repl_list = [list() for i in range(0, 11, 1)] \n",
    "## Filter by the level of punishment, is this the same behaviour across all 3 levels?\n",
    "#punish_val = \"BIC\"\n",
    "#filtered_by_param_punish = group_by(all_results, '/results/attributes/parameter_punishment', punish_val)\n",
    "#fig, axs = plt.subplots(1, len(dataset_sizes), sharey=True)\n",
    "for key in [\"Laplace\", \"Laplace_prior\", \"BIC\", \"AIC\"]:\n",
    "    all_results = load_results('results', key)\n",
    "    if key in [\"Laplace_prior\"]:\n",
    "    for punish_val in [0.0, 2.0, \"BIC\"]:\n",
    "        print(punish_val)\n",
    "        print(key)\n",
    "        result_tree = generate_tree_structure(all_results[0]).descendants\n",
    "        avg_additional_punish = list()#[list() for i in range(0, 11, 1)]\n",
    "        param_num_list = list()#[list() for i in range(0, 11, 1)] \n",
    "        punish_without_repl_list = [list() for i in range(0, 11, 1)] \n",
    "        # Filter by the level of punishment, is this the same behaviour across all 3 levels?\n",
    "        filtered_by_param_punish = group_by(all_results, '/results/attributes/parameter_punishment', punish_val)\n",
    "        fig, axs = plt.subplots(1, len(dataset_sizes), sharey=True)\n",
    "        for i, data_num in enumerate(dataset_sizes):\n",
    "            print(data_num)\n",
    "            group_by_size = group_by(filtered_by_param_punish[list(filtered_by_param_punish.keys())[0]], '/results/attributes/eval_COUNT', data_num)\n",
    "            avg_additional_punish = list()#[list() for i in range(0, 11, 1)]\n",
    "            param_num_list = list()#[list() for i in range(0, 11, 1)] \n",
    "            for result in group_by_size[list(group_by_size.keys())[0]]:\n",
    "                details = deep_dict_get(result, \"/results/results/details\")\n",
    "                # iterate over all kernels that were tried in the kernel search\n",
    "                for tried_kernel in details:\n",
    "                    if key == \"Laplace\":\n",
    "                        new_val = (tried_kernel[\"punish without replacement\"] - tried_kernel[\"punish term\"])[0][0]#/tried_kernel[\"num_replaced\"])\n",
    "                    else:\n",
    "                        new_val = (tried_kernel[\"punish without replacement\"] - tried_kernel[\"punish term\"])#/tried_kernel[\"num_replaced\"])\n",
    "                    if not new_val > 10000:\n",
    "                        avg_additional_punish.append(new_val) \n",
    "                        param_num_list.append(len(tried_kernel[\"parameter list\"]))\n",
    "                    #punish_without_repl_list[len(tried_kernel[\"parameter list\"])].append(tried_kernel[\"punish without replacement\"])\n",
    "                    #param_num_list[len(tried_kernel[\"parameter list\"])].append(tried_kernel[\"num_replaced\"])\n",
    "            #plt.violinplot(param_num_list[3:], positions=range(3, 11))\n",
    "            print(f\"Total tried kernels: {len(avg_additional_punish)} - NaNs: {torch.count_nonzero(torch.Tensor([torch.isnan(p) for p in avg_additional_punish]))}\")\n",
    "            axs[i].scatter(param_num_list, avg_additional_punish)\n",
    "            axs[i].plot([2.9,9.1], [0,0], color=\"red\")\n",
    "            #print(avg_additional_punish)\n",
    "            #param_num_list\n",
    "\n",
    "        fig.set_figwidth(20)\n",
    "        fig.set_figheight(4)\n",
    "            \n",
    "        #plt.ylabel(\"oldHessian punish - newHessian punish\")\n",
    "        axs[0].set_ylabel(\"oldHessian punish - newHessian punish\")\n",
    "        axs[2].set_xlabel(\"num parameters\")\n",
    "        plt.savefig(f\"evaluation/param_punish_difference_{key}_level_{punish_val}.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931e5497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the recognition ratio of \"PER\", \"MAT32\", \"PER*SE\", \"PER+SE\", \"MAT32*PER\", \"MAT32+PER\"\n",
    "keys = [\"AIC\", \"MLL\", \"Laplace\", \"BIC\"]\n",
    "all_keys = keys + [\"Laplace_prior\"]\n",
    "kernel_distributions = {}\n",
    "avg_mlls = {key:list() for key in all_keys} \n",
    "avg_mlls_retrained = {key:list() for key in keys}\n",
    "for key in keys:\n",
    "    print(key)\n",
    "    all_results = load_results('results', key, regex_scheme=\"0.pickle\")\n",
    "    result_tree = generate_tree_structure(all_results[0]).descendants\n",
    "    data_num = 10\n",
    "    data_500 = group_by(all_results, '/results/attributes/eval_COUNT', data_num)\n",
    "    #data_0_punish = group_by(all_results, '/results/attributes/parameter_punishment', 0.0)\n",
    "\n",
    "    for result in data_500[f\"/results/attributes/eval_COUNT = {data_num}\"]:\n",
    "        avg_mll = deep_dict_get(result, \"/results/results/avg test mll\")\n",
    "        if not np.isnan(avg_mll):\n",
    "            if not np.isnan(torch.log(-avg_mll)):\n",
    "                avg_mlls[key].append(avg_mll)\n",
    "            else:\n",
    "                print(\"THERE WAS SOMETHING POSITIVE!!!!\")\n",
    "print(\"Laplace_prior\")\n",
    "all_results = load_results('results', \"Laplace_prior\", regex_scheme=\"0.pickle\")\n",
    "result_tree = generate_tree_structure(all_results[0]).descendants\n",
    "#data_500 = group_by(all_results, '/results/attributes/eval_COUNT', 500)\n",
    "data_0_punish = group_by_multiple(all_results, {'/results/attributes/parameter_punishment': 0.0, '/results/attributes/eval_COUNT': data_num})\n",
    "\n",
    "for result in data_0_punish[list(data_0_punish.keys())[0]]: #data_500[\"/results/attributes/eval_COUNT = 500\"]:\n",
    "    avg_mll = deep_dict_get(result, \"/results/results/avg test mll\")\n",
    "    if not np.isnan(avg_mll):\n",
    "        if not np.isnan(torch.log(-avg_mll)):\n",
    "            avg_mlls[\"Laplace_prior\"].append(avg_mll)\n",
    "        else:\n",
    "            print(\"THERE WAS SOMETHING POSITIVE!!!!\")\n",
    "\n",
    "\n",
    "\n",
    "        #avg_mll_retrained = deep_dict_get(result, \"/results/results/avg test mll retrained\")\n",
    "        #if not np.isnan(avg_mll_retrained):\n",
    "        #    avg_mlls_retrained[key].append(avg_mll_retrained)\n",
    "plt.boxplot([avg_mlls[key] for key in all_keys], labels=[f\"{key}-AVG\" for key in all_keys], positions=range(len(all_keys)), showfliers=False)\n",
    "#plt.violinplot([avg_mlls[key] for key in all_keys])#, labels=[f\"{key}-AVG\" for key in all_keys], positions=range(len(all_keys)))\n",
    "#plt.boxplot([avg_mlls_retrained[key] for key in keys], labels=[f\"{key}-AVG-R\" for key in keys], positions=range(len(keys), 2*len(keys), 1))\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379ead81",
   "metadata": {},
   "outputs": [],
   "source": [
    "punish_level = 2.0\n",
    "for data_num in [10, 20,, 30, 40, 50]:#, 70, 100, 150, 200]:\n",
    "    keys = [\"AIC\", \"MLL\", \"BIC\"]\n",
    "    add_keys = [\"Laplace_prior\", \"Laplace\"]\n",
    "    all_keys = keys + add_keys\n",
    "    kernel_distributions = {}\n",
    "    avg_mlls = {key:list() for key in all_keys} \n",
    "    avg_mlls_retrained = {key:list() for key in keys}\n",
    "    for key in keys:\n",
    "        print(key)\n",
    "        all_results = load_results('results', key)#, regex_scheme=\"[0-9].pickle\")\n",
    "        result_tree = generate_tree_structure(all_results[0]).descendants\n",
    "        #data_500 = group_by(all_results, '/results/attributes/Data_kernel','CO2')\n",
    "        data_500 = group_by(all_results, '/results/attributes/eval_COUNT', data_num)\n",
    "        #data_0_punish = group_by(all_results, '/results/attributes/parameter_punishment', 0.0)\n",
    "\n",
    "        for result in data_500[f\"/results/attributes/eval_COUNT = {data_num}\"]:\n",
    "            avg_mll = deep_dict_get(result, \"/results/results/avg test mll\")\n",
    "            if not np.isnan(avg_mll):\n",
    "                avg_mlls[key].append(avg_mll)\n",
    "    for key in add_keys:\n",
    "        print(key)\n",
    "        all_results = load_results('results', key)#, regex_scheme=\"[0-9].pickle\")\n",
    "        result_tree = generate_tree_structure(all_results[0]).descendants\n",
    "        data_0_punish = group_by_multiple(all_results, {'/results/attributes/parameter_punishment': punish_level, '/results/attributes/eval_COUNT': data_num})\n",
    "        #data_0_punish = group_by(all_results, '/results/attributes/parameter_punishment', 0.0)\n",
    "\n",
    "        for result in data_0_punish[list(data_0_punish.keys())[0]]:\n",
    "            avg_mll = deep_dict_get(result, \"/results/results/avg test mll\")\n",
    "            if not np.isnan(avg_mll):\n",
    "                avg_mlls[key].append(avg_mll)\n",
    "    #data_500 = group_by(all_results, '/results/attributes/eval_COUNT', 500)\n",
    "            #avg_mll_retrained = deep_dict_get(result, \"/results/results/avg test mll retrained\")\n",
    "            #if not np.isnan(avg_mll_retrained):\n",
    "            #    avg_mlls_retrained[key].append(avg_mll_retrained)\n",
    "    plt.boxplot([avg_mlls[key] for key in all_keys], labels=[f\"{key}-AVG\" for key in all_keys], positions=range(len(all_keys)), showfliers=False)\n",
    "    #plt.violinplot([avg_mlls[key] for key in all_keys])#, labels=[f\"{key}-AVG\" for key in all_keys], positions=range(len(all_keys)))\n",
    "    #plt.boxplot([avg_mlls_retrained[key] for key in keys], labels=[f\"{key}-AVG-R\" for key in keys], positions=range(len(keys), 2*len(keys), 1))\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"evaluation/{data_num}_log-likelihood_boxplot_{punish_level}-punish.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6597408",
   "metadata": {},
   "source": [
    "# Kernel sizes across metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c7c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b570a8ca",
   "metadata": {},
   "source": [
    "# Distribution of kernels per metric/data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584769ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"Laplace0.0\", \"Laplace2.0\", \"LaplaceBIC\",  \"AIC\", \"BIC\", \"Laplace_prior0.0\", \"Laplace_prior2.0\", \"Laplace_priorBIC\"]\n",
    "keys = [ \"AIC\", \"BIC\"]\n",
    "all_keys = keys + [\"Laplace_prior\", \"Laplace\"]\n",
    "\n",
    "data_sizes = [10, 20, 30, 40, 50, 70, 100, 150, 200]\n",
    "\n",
    "all_kernel_distributions = {data_num : {metric : {} for metric in \n",
    "                                       [\"Laplace0.0\", \"Laplace2.0\", \"LaplaceBIC\",  \"AIC\", \"BIC\", \"Laplace_prior0.0\", \"Laplace_prior2.0\", \"Laplace_priorBIC\"]}\n",
    "                            for data_num in [10, 20, 30, 40, 50, 70, 100, 150, 200]}\n",
    "for key in all_keys:\n",
    "    print(key)\n",
    "    all_results = load_results('results', key)#, regex_scheme=r_scheme)\n",
    "    for data_num in data_sizes:\n",
    "        data = group_by(all_results, '/results/attributes/eval_COUNT', data_num)\n",
    "        data_keys = list(data.keys())\n",
    "        if key in [\"Laplace_prior\", \"Laplace\"]:\n",
    "            data = group_by(data[data_keys[0]], '/results/attributes/parameter_punishment') \n",
    "        for data_key in data:\n",
    "            found_kernels_dict = {}\n",
    "            for result in data[data_key]:\n",
    "                final_model = deep_dict_get(result, 'results/results/final model')\n",
    "                # Clean up kernel expression\n",
    "                temp = final_model.replace(\"(\", \"\")\n",
    "                temp = temp.replace(\")\", \"\")\n",
    "                temp = temp.replace(\" \", \"\")\n",
    "                temp = temp.replace(\"c*\", \"\")\n",
    "                # Sort the lists and sublists\n",
    "                temp_list = [(sorted(s.split(\"*\"))) for s in sorted(temp.split(\"+\"))]\n",
    "                final_model = \"+\".join([\"*\".join([s for s in sublist]) for sublist in temp_list])\n",
    "                if not final_model in found_kernels_dict:\n",
    "                    found_kernels_dict[final_model] = 1\n",
    "                else:\n",
    "                    found_kernels_dict[final_model] += 1\n",
    "            # sanity check for number of entries\n",
    "            if not sum([found_kernels_dict[k] for k in found_kernels_dict]) == 400:\n",
    "                print(metric)\n",
    "                print(data_num)\n",
    "                print(sum([found_kernels_dict[k] for k in found_kernels_dict]))\n",
    "            if key in [\"Laplace_prior\", \"Laplace\"]:\n",
    "                all_kernel_distributions[data_num][f\"{key}{data_key.split('=')[-1][1:]}\"] = found_kernels_dict \n",
    "            else:\n",
    "                all_kernel_distributions[data_num][f\"{key}\"] = found_kernels_dict\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef45ebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_kernel_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972b8eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the kernel size in terms of kernel entries\n",
    "\n",
    "simplified_kernel_distributions = {data_num : {metric : {1: 0, 2:0, 3:0} for metric in \n",
    "                                       [\"Laplace0.0\", \"Laplace2.0\", \"LaplaceBIC\",  \"AIC\", \"BIC\", \"Laplace_prior0.0\", \"Laplace_prior2.0\", \"Laplace_priorBIC\"]}\n",
    "                            for data_num in [10, 20, 30, 40, 50, 70, 100, 150, 200]}\n",
    "for data_num in all_kernel_distributions:\n",
    "    for metric in all_kernel_distributions[data_num]:\n",
    "        for found_kernel in all_kernel_distributions[data_num][metric]:\n",
    "            # Get rid of all the constants\n",
    "            #temp = found_kernel.replace(\"(\", \"\")\n",
    "            #temp = temp.replace(\")\", \"\")\n",
    "            #temp = temp.replace(\" \", \"\")\n",
    "            #temp = temp.replace(\"c*\", \"\")\n",
    "            covar_string_list = [s.split(\"*\") for s in found_kernel.split(\"+\")]\n",
    "            #temp_list = [(sorted([s.split(\"*\")])) for s in sorted(found_kernel.split(\"+\"))]\n",
    "            #\"+\".join([\"*\".join([s for s in sublist]) for sublist in temp_list])\n",
    "            simplified_kernel_distributions[data_num][metric][len(covar_string_list)] += all_kernel_distributions[data_num][metric][found_kernel]\n",
    "        \n",
    "simplified_kernel_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5dc1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce barplots for the summarized distributions\n",
    "fig, axs = plt.subplots(len([10, 20, 30, 40, 50, 70, 100, 150, 200]),\n",
    "                        len(simplified_kernel_distributions[10]), sharey=True)\n",
    "for row, data_num in enumerate([10, 20, 30, 40, 50, 70, 100, 150, 200]):\n",
    "    for col, metric in enumerate(simplified_kernel_distributions[data_num]):\n",
    "        if row == 0:\n",
    "            axs[row, col].set_title(metric)\n",
    "        if col == 0:\n",
    "            axs[row, col].set_ylabel(data_num)\n",
    "        axs[row, col].bar(range(len(list(simplified_kernel_distributions[data_num][metric].keys()))),\n",
    "                          [simplified_kernel_distributions[data_num][metric][k] for k in simplified_kernel_distributions[data_num][metric]],\n",
    "                          tick_label=list(simplified_kernel_distributions[data_num][metric].keys()))\n",
    "        #axs[row, col].tick_params('x', labelrotation=90)\n",
    "        #plt.xticks(range(len(list(simplified_kernel_distributions[data_num][metric].keys()))), rotation=90)\n",
    "\n",
    "fig.set_figwidth(15)\n",
    "fig.set_figheight(10)\n",
    "fig.tight_layout()\n",
    "tikzplotlib.save(\"evaluation/kernel_distribution_summarized.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cdc114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce barplots for the detailed distributions\n",
    "fig, axs = plt.subplots(4,#len(all_kernel_distributions),\n",
    "                        len(all_kernel_distributions[10]), sharey=True)\n",
    "#for row, data_num in enumerate(all_kernel_distributions):\n",
    "#[10, 20, 30, 40, 50, 70, 100, 150, 200]\n",
    "for row, data_num in enumerate([10, 20, 30, 40]):\n",
    "    for col, metric in enumerate(all_kernel_distributions[data_num]):\n",
    "        if row == 0:\n",
    "            axs[row, col].set_title(metric)\n",
    "        if col == 0:\n",
    "            axs[row, col].set_ylabel(data_num)\n",
    "        axs[row, col].bar(range(len(list(all_kernel_distributions[data_num][metric].keys()))),\n",
    "                          [all_kernel_distributions[data_num][metric][k] for k in sorted(all_kernel_distributions[data_num][metric], key=len, reverse=False)],\n",
    "                          tick_label=list(sorted(all_kernel_distributions[data_num][metric], key=len, reverse=False)))\n",
    "        axs[row, col].tick_params('x', labelrotation=90)\n",
    "        #plt.xticks(range(len(list(all_kernel_distributions[data_num][metric].keys()))), rotation=90)\n",
    "fig.set_figwidth(30)\n",
    "fig.set_figheight(15)\n",
    "fig.tight_layout()\n",
    "\n",
    "tikzplotlib.save(\"evaluation/kernel_distribution_small_datasizes.tex\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "805571d0",
   "metadata": {},
   "source": [
    "# Recognition ratio and avg. MLL plots/tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5379fda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_results = {data_num : {metric : {} for metric in \n",
    "                                       [\"Laplace0.0\", \"Laplace2.0\", \"LaplaceBIC\",  \"AIC\", \"BIC\", \"Laplace_prior0.0\", \"Laplace_prior2.0\", \"Laplace_priorBIC\"]}\n",
    "                            for data_num in [5, 10, 20, 30, 40, 50, 70, 100, 150, 200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c2b06e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC\n",
      "BIC\n",
      "Laplace_prior\n",
      "Laplace\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "# Create table for evaluation\n",
    "#################\n",
    "keys = [ \"AIC\", \"BIC\"]# \"MLL\",\n",
    "all_keys = keys + [\"Laplace_prior\", \"Laplace\"]\n",
    "#all_keys = [\"Laplace_prior\"]\n",
    "\n",
    "#datasizes = [10, 50, 100, 250, 500]\n",
    "r_scheme = \"[0-29].pickle\"\n",
    "datasizes = [5, 10, 20, 30, 40, 50, 70, 100, 150, 200]\n",
    "metrics = [\"AIC\", \"BIC\", \"Laplace_prior0.0\", \"Laplace_prior2.0\", \"Laplace_priorBIC\", \"Laplace0.0\", \"Laplace2.0\", \"LaplaceBIC\"]\n",
    "#param_punish = 0.0 \n",
    "for key in all_keys:\n",
    "    print(key)\n",
    "    all_results = load_results('results', key)#, regex_scheme=r_scheme)\n",
    "    result_tree = generate_tree_structure(all_results[0]).descendants\n",
    "    kernel_distributions = {}\n",
    "    for data_num in datasizes:\n",
    "        avg_mlls = {key:list() for key in metrics} \n",
    "        if key in [\"Laplace_prior\", \"Laplace\"]:\n",
    "            for param_punish in [0.0, 2.0, \"BIC\"]:\n",
    "                data_500 = group_by_multiple(all_results, {'/results/attributes/parameter_punishment': param_punish, '/results/attributes/eval_COUNT': data_num})\n",
    "                for result in data_500[list(data_500.keys())[0]]:\n",
    "                    avg_mll = deep_dict_get(result, \"/results/results/avg test mll\")\n",
    "                    if not np.isnan(avg_mll):\n",
    "                        avg_mlls[f\"{key}{param_punish}\"].append(avg_mll)\n",
    "                total_results[data_num][f\"{key}{param_punish}\"][\"median\"] = np.median(avg_mlls[f\"{key}{param_punish}\"])\n",
    "                total_results[data_num][f\"{key}{param_punish}\"][\"Q1\"] = np.quantile(avg_mlls[f\"{key}{param_punish}\"], 0.33)\n",
    "                total_results[data_num][f\"{key}{param_punish}\"][\"Q3\"] = np.quantile(avg_mlls[f\"{key}{param_punish}\"], 0.66)\n",
    "        else:\n",
    "            data_500 = group_by(all_results, '/results/attributes/eval_COUNT', data_num)\n",
    "            for result in data_500[list(data_500.keys())[0]]:\n",
    "                avg_mll = deep_dict_get(result, \"/results/results/avg test mll\")\n",
    "                if not np.isnan(avg_mll):\n",
    "                    avg_mlls[key].append(avg_mll)\n",
    "            total_results[data_num][key][\"median\"] = np.median(avg_mlls[key])\n",
    "            total_results[data_num][key][\"Q1\"] = np.quantile(avg_mlls[key], 0.33)\n",
    "            total_results[data_num][key][\"Q3\"] = np.quantile(avg_mlls[key], 0.66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95247f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: {'Laplace0.0': {},\n",
       "  'Laplace2.0': {},\n",
       "  'LaplaceBIC': {},\n",
       "  'AIC': {},\n",
       "  'BIC': {},\n",
       "  'Laplace_prior0.0': {},\n",
       "  'Laplace_prior2.0': {},\n",
       "  'Laplace_priorBIC': {}},\n",
       " 10: {'Laplace0.0': {'median': -0.5638637,\n",
       "   'Q1': -1.2910209035873412,\n",
       "   'Q3': 0.2136188599467278},\n",
       "  'Laplace2.0': {'median': -0.3639787,\n",
       "   'Q1': -1.3179158306121825,\n",
       "   'Q3': 0.3059341037273408},\n",
       "  'LaplaceBIC': {'median': -0.5293194,\n",
       "   'Q1': -1.287655782699585,\n",
       "   'Q3': 0.41870648562908225},\n",
       "  'AIC': {'median': -0.13411152,\n",
       "   'Q1': -1.3061450707912445,\n",
       "   'Q3': 0.8159529554843916},\n",
       "  'BIC': {'median': -0.7145959,\n",
       "   'Q1': -1.465972625017166,\n",
       "   'Q3': 0.39675737857818655},\n",
       "  'Laplace_prior0.0': {'median': 0.14193709,\n",
       "   'Q1': -1.0242484951019286,\n",
       "   'Q3': 1.0462250161170963},\n",
       "  'Laplace_prior2.0': {'median': -0.5900798,\n",
       "   'Q1': -1.3935364830493926,\n",
       "   'Q3': 0.3484532821178439},\n",
       "  'Laplace_priorBIC': {'median': -0.6211333,\n",
       "   'Q1': -1.3415072584152221,\n",
       "   'Q3': 0.2916986995935451}},\n",
       " 20: {'Laplace0.0': {'median': 0.57901144,\n",
       "   'Q1': 0.24222691968083385,\n",
       "   'Q3': 0.8454752349853517},\n",
       "  'Laplace2.0': {'median': 0.60113364,\n",
       "   'Q1': 0.19635339796543125,\n",
       "   'Q3': 0.8328669154644013},\n",
       "  'LaplaceBIC': {'median': 0.58526266,\n",
       "   'Q1': 0.1536274269223216,\n",
       "   'Q3': 0.8441140234470368},\n",
       "  'AIC': {'median': 0.66978323,\n",
       "   'Q1': 0.09264910034835341,\n",
       "   'Q3': 0.8963314425945283},\n",
       "  'BIC': {'median': 0.5517851,\n",
       "   'Q1': -0.24787325501441948,\n",
       "   'Q3': 0.8836191356182099},\n",
       "  'Laplace_prior0.0': {'median': 0.7186488,\n",
       "   'Q1': 0.3112378081679346,\n",
       "   'Q3': 0.9665293908119202},\n",
       "  'Laplace_prior2.0': {'median': 0.6390046,\n",
       "   'Q1': 0.18672945156693463,\n",
       "   'Q3': 0.8529224205017091},\n",
       "  'Laplace_priorBIC': {'median': 0.58887947,\n",
       "   'Q1': -0.27980946987867333,\n",
       "   'Q3': 0.8515053725242616}},\n",
       " 30: {'Laplace0.0': {'median': 0.83211625,\n",
       "   'Q1': 0.6174219274520877,\n",
       "   'Q3': 0.9332529628276827},\n",
       "  'Laplace2.0': {'median': 0.81920755,\n",
       "   'Q1': 0.6276820373535157,\n",
       "   'Q3': 0.9334420979022979},\n",
       "  'LaplaceBIC': {'median': 0.82740325,\n",
       "   'Q1': 0.6264805686473847,\n",
       "   'Q3': 0.9317601203918457},\n",
       "  'AIC': {'median': 0.82868135,\n",
       "   'Q1': 0.6170007556676865,\n",
       "   'Q3': 0.9385267281532288},\n",
       "  'BIC': {'median': 0.82773846,\n",
       "   'Q1': 0.6428547722101212,\n",
       "   'Q3': 0.9276547312736512},\n",
       "  'Laplace_prior0.0': {'median': 0.81767184,\n",
       "   'Q1': 0.6146786236763001,\n",
       "   'Q3': 0.9560051441192627},\n",
       "  'Laplace_prior2.0': {'median': 0.83623445,\n",
       "   'Q1': 0.5728558665513992,\n",
       "   'Q3': 0.9467901742458343},\n",
       "  'Laplace_priorBIC': {'median': 0.8526392,\n",
       "   'Q1': 0.6261017686128618,\n",
       "   'Q3': 0.959799634218216}},\n",
       " 40: {'Laplace0.0': {'median': 0.89308923,\n",
       "   'Q1': 0.8128583115339281,\n",
       "   'Q3': 0.9636195993423462},\n",
       "  'Laplace2.0': {'median': 0.8998989,\n",
       "   'Q1': 0.7912285310029985,\n",
       "   'Q3': 0.9583494806289673},\n",
       "  'LaplaceBIC': {'median': 0.8784758,\n",
       "   'Q1': 0.7498998272418976,\n",
       "   'Q3': 0.9373545300960541},\n",
       "  'AIC': {'median': 0.8816662,\n",
       "   'Q1': 0.7444102853536606,\n",
       "   'Q3': 0.9455623412132264},\n",
       "  'BIC': {'median': 0.9081155,\n",
       "   'Q1': 0.8179370254278183,\n",
       "   'Q3': 0.9790466821193698},\n",
       "  'Laplace_prior0.0': {'median': 0.9082955,\n",
       "   'Q1': 0.7582719999551774,\n",
       "   'Q3': 1.0079227519035339},\n",
       "  'Laplace_prior2.0': {'median': 0.9022413,\n",
       "   'Q1': 0.8145769065618516,\n",
       "   'Q3': 0.973336284160614},\n",
       "  'Laplace_priorBIC': {'median': 0.89337754,\n",
       "   'Q1': 0.7997784161567688,\n",
       "   'Q3': 0.9546607887744903}},\n",
       " 50: {'Laplace0.0': {'median': 0.9167808,\n",
       "   'Q1': 0.8692176669836045,\n",
       "   'Q3': 0.9890878224372864},\n",
       "  'Laplace2.0': {'median': 0.90965265,\n",
       "   'Q1': 0.8521329522132874,\n",
       "   'Q3': 0.9677163577079774},\n",
       "  'LaplaceBIC': {'median': 0.90279657,\n",
       "   'Q1': 0.8341446429491044,\n",
       "   'Q3': 0.9558190739154817},\n",
       "  'AIC': {'median': 0.9072123,\n",
       "   'Q1': 0.8349554598331451,\n",
       "   'Q3': 0.9712236940860748},\n",
       "  'BIC': {'median': 0.9037148,\n",
       "   'Q1': 0.8321063858270645,\n",
       "   'Q3': 0.9735908699035646},\n",
       "  'Laplace_prior0.0': {'median': 0.9160985,\n",
       "   'Q1': 0.8488607221841812,\n",
       "   'Q3': 0.9883790230751038},\n",
       "  'Laplace_prior2.0': {'median': 0.92682177,\n",
       "   'Q1': 0.8770061725378037,\n",
       "   'Q3': 1.0335914325714113},\n",
       "  'Laplace_priorBIC': {'median': 0.9160167,\n",
       "   'Q1': 0.8660295844078064,\n",
       "   'Q3': 1.0003587412834167}},\n",
       " 70: {'Laplace0.0': {'median': 0.9193655,\n",
       "   'Q1': 0.8851175385713578,\n",
       "   'Q3': 0.9736331415176391},\n",
       "  'Laplace2.0': {'median': 0.9202051,\n",
       "   'Q1': 0.8848994708061219,\n",
       "   'Q3': 0.9598885142803192},\n",
       "  'LaplaceBIC': {'median': 0.9130312,\n",
       "   'Q1': 0.8716311198472977,\n",
       "   'Q3': 0.9576949679851532},\n",
       "  'AIC': {'median': 0.9178574,\n",
       "   'Q1': 0.8702881336212158,\n",
       "   'Q3': 0.9624189281463624},\n",
       "  'BIC': {'median': 0.929754,\n",
       "   'Q1': 0.8931610321998597,\n",
       "   'Q3': 0.9729491722583771},\n",
       "  'Laplace_prior0.0': {'median': 0.9154019,\n",
       "   'Q1': 0.8740444993972778,\n",
       "   'Q3': 0.9745336794853211},\n",
       "  'Laplace_prior2.0': {'median': 0.9222168,\n",
       "   'Q1': 0.8843518435955048,\n",
       "   'Q3': 0.963917373418808},\n",
       "  'Laplace_priorBIC': {'median': 0.92282236,\n",
       "   'Q1': 0.8911743867397308,\n",
       "   'Q3': 0.9790976417064667}},\n",
       " 100: {'Laplace0.0': {'median': 0.9170979,\n",
       "   'Q1': 0.8863318902254105,\n",
       "   'Q3': 0.9451927065849305},\n",
       "  'Laplace2.0': {'median': 0.91823846,\n",
       "   'Q1': 0.8944409012794494,\n",
       "   'Q3': 0.944407571554184},\n",
       "  'LaplaceBIC': {'median': 0.92132866,\n",
       "   'Q1': 0.8916096019744874,\n",
       "   'Q3': 0.9496616554260254},\n",
       "  'AIC': {'median': 0.9141808,\n",
       "   'Q1': 0.8841906577348709,\n",
       "   'Q3': 0.9460922694206239},\n",
       "  'BIC': {'median': 0.9221624,\n",
       "   'Q1': 0.8934360116720199,\n",
       "   'Q3': 0.950301684141159},\n",
       "  'Laplace_prior0.0': {'median': 0.9184292,\n",
       "   'Q1': 0.8815084451436996,\n",
       "   'Q3': 0.9561757397651672},\n",
       "  'Laplace_prior2.0': {'median': 0.9162552,\n",
       "   'Q1': 0.8899163728952408,\n",
       "   'Q3': 0.9475705873966217},\n",
       "  'Laplace_priorBIC': {'median': 0.92258155,\n",
       "   'Q1': 0.8974668258428574,\n",
       "   'Q3': 0.9498507559299469}},\n",
       " 150: {'Laplace0.0': {'median': 0.9057585,\n",
       "   'Q1': 0.888739503622055,\n",
       "   'Q3': 0.9251930141448975},\n",
       "  'Laplace2.0': {'median': 0.91473377,\n",
       "   'Q1': 0.89355175614357,\n",
       "   'Q3': 0.9291534066200257},\n",
       "  'LaplaceBIC': {'median': 0.90993357,\n",
       "   'Q1': 0.8908241128921509,\n",
       "   'Q3': 0.9253215408325195},\n",
       "  'AIC': {'median': 0.9065371,\n",
       "   'Q1': 0.888986560702324,\n",
       "   'Q3': 0.9250731658935547},\n",
       "  'BIC': {'median': 0.90796936,\n",
       "   'Q1': 0.8883637201786041,\n",
       "   'Q3': 0.9267930734157562},\n",
       "  'Laplace_prior0.0': {'median': 0.9053985,\n",
       "   'Q1': 0.8868900781869888,\n",
       "   'Q3': 0.9228273856639863},\n",
       "  'Laplace_prior2.0': {'median': 0.9088751,\n",
       "   'Q1': 0.892277267575264,\n",
       "   'Q3': 0.9260495948791504},\n",
       "  'Laplace_priorBIC': {'median': 0.9117441,\n",
       "   'Q1': 0.8944901919364929,\n",
       "   'Q3': 0.9278173696994781}},\n",
       " 200: {'Laplace0.0': {'median': 0.90573037,\n",
       "   'Q1': 0.891148235797882,\n",
       "   'Q3': 0.9164016819000245},\n",
       "  'Laplace2.0': {'median': 0.9045557,\n",
       "   'Q1': 0.8900252991914749,\n",
       "   'Q3': 0.9162922954559326},\n",
       "  'LaplaceBIC': {'median': 0.9045155,\n",
       "   'Q1': 0.8922210848331451,\n",
       "   'Q3': 0.9147805857658386},\n",
       "  'AIC': {'median': 0.8993432,\n",
       "   'Q1': 0.8857832443714142,\n",
       "   'Q3': 0.9131260323524475},\n",
       "  'BIC': {'median': 0.9063263,\n",
       "   'Q1': 0.8920054429769516,\n",
       "   'Q3': 0.9168135452270508},\n",
       "  'Laplace_prior0.0': {'median': 0.900517,\n",
       "   'Q1': 0.8871172523498535,\n",
       "   'Q3': 0.9151723003387451},\n",
       "  'Laplace_prior2.0': {'median': 0.905597,\n",
       "   'Q1': 0.8917703360319138,\n",
       "   'Q3': 0.9160067021846772},\n",
       "  'Laplace_priorBIC': {'median': 0.9030422,\n",
       "   'Q1': 0.8899660611152649,\n",
       "   'Q3': 0.9149209463596344}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85d164bf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fb562cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC\n",
      "BIC\n",
      "Laplace_prior0.0\n",
      "Laplace_prior2.0\n",
      "Laplace_priorBIC\n",
      "Laplace0.0\n",
      "Laplace2.0\n",
      "LaplaceBIC\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9950047280>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matplotlib plot with fill between Q1 and Q3 and the median as the base values\n",
    "metrics = [\"Laplace\"]#[ \"AIC\", \"BIC\", \"Laplace_prior\", \"Laplace\"]#\"MLL\",\n",
    "metrics = [ \"AIC\", \"BIC\", \"Laplace_prior\", \"Laplace\"]#\"MLL\",\n",
    "metrics = [\"AIC\", \"BIC\", \"Laplace_prior0.0\", \"Laplace_prior2.0\", \"Laplace_priorBIC\", \"Laplace0.0\", \"Laplace2.0\", \"LaplaceBIC\"]\n",
    "#lines = ['', ' ', '--', '-.', '-', ':']\n",
    "fig, ax = plt.subplots()\n",
    "for metric in metrics:\n",
    "    print(metric)\n",
    "    medians = [total_results[k][metric][\"median\"] for k in total_results]\n",
    "    lower = [total_results[k][metric][\"Q1\"] for k in total_results]\n",
    "    upper = [total_results[k][metric][\"Q3\"] for k in total_results]\n",
    "    x = [k for k in total_results]\n",
    "    lw = 2.0 if any(text in metric for text in [\"Laplace\", \"Laplace_prior\"]) else 1.0\n",
    "    ax.plot(x, medians, label=metric, linewidth=lw)\n",
    "    #ax.errorbar(x, medians, yerr=[u-l for l, u in zip(lower, upper)])\n",
    "    ax.fill_between(x, lower, upper, alpha=0.2)\n",
    "plt.legend()\n",
    "#plt.savefig(\"evaluation/mll_per_datapoint_full.png\")\n",
    "#tikzplotlib.save(\"evaluation/mll_per_datapoint_full.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6939c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a66ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca57570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([kernel for kernel in ['AIC', 'BIC', 'Laplace_prior0.0', 'Laplace_prior2.0', 'Laplace_priorBIC', 'Laplace0.0', 'Laplace2.0', 'LaplaceBIC']])\n",
    "for data_num in total_results:\n",
    "    print(f\"{data_num} & {' & '.join([str(total_results[data_num][kernel]['median']) for kernel in ['AIC', 'BIC', 'Laplace_prior0.0', 'Laplace_prior2.0', 'Laplace_priorBIC', 'Laplace0.0', 'Laplace2.0', 'LaplaceBIC']])} \\\\\\\\\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51ec27ca",
   "metadata": {},
   "source": [
    "# CO2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c87e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in [\"MLL\", \"AIC\", \"BIC\", \"Laplace\", \"Laplace_prior\"]:\n",
    "    print(key)\n",
    "    all_results = load_results('results/CO2',  key)#, regex_scheme=r_scheme)\n",
    "    for i, result in enumerate(all_results):\n",
    "        print(i)\n",
    "        if key in [\"Laplace\", \"Laplace_prior\"]:\n",
    "            print(deep_dict_get(result, \"results/attributes/parameter_punishment\"))\n",
    "        print(deep_dict_get(result, \"results/results/test mll\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17acf0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_results = load_results('results', \"Laplace\")#, regex_scheme=\"[0-9].pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
