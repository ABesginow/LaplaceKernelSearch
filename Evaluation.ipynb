{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16826c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting anytree\n",
      "  Using cached anytree-2.8.0-py2.py3-none-any.whl (41 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/besginow/anaconda3/envs/sage/lib/python3.10/site-packages (from anytree) (1.16.0)\n",
      "Installing collected packages: anytree\n",
      "Successfully installed anytree-2.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install anytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c252e947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pprint\n",
    "from anytree import Node, RenderTree\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca837a3",
   "metadata": {},
   "source": [
    "For future iterations of this I might change the scheme to a deep directory based approach.    \n",
    "Then iterations would be named `1.pickle`, `2.pickle` and be stored in deep directories like:    \n",
    "`\"Experiment_name/config1/config2/config3/config4/1.pickle\"`    \n",
    "This way I could just split the name accross the folder separator and have all the setting values, then the only thing I need is a list that gives me the correct setting-value assignment, which sounds a lot easier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa87acf",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bb3e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(filepath : str):\n",
    "    file_object = open(filepath, \"rb\")\n",
    "    results = pickle.load(file_object)\n",
    "    file_object.close()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9256daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_setting_from_name(name :str, naming_schema : list):\n",
    "    result = {}\n",
    "    # Main assumption for the naming schema: parameters are strictly separated by underscores '_'\n",
    "    for value, setting in zip(name.split(\"_\"), naming_schema):\n",
    "        result[setting] = value\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "02415768",
   "metadata": {},
   "source": [
    "class Tree:\n",
    "    def __init__(self, leaves : list, parent=None):\n",
    "        self.parent = parent\n",
    "        self.leaves = leaves\n",
    "\n",
    "        \n",
    "    def recursive_tree_print(self, root):\n",
    "        line = \"\"\n",
    "        for branch in root:\n",
    "            if type(branch) == Tree:\n",
    "                line += f\"{branch} -\"\n",
    "                line += self.recursive_tree_print(branch)\n",
    "            elif type(branch) == list:\n",
    "                for b in branch:\n",
    "                    line += b + \"\\t\"\n",
    "            else:\n",
    "                line += branch + \"\\t\"\n",
    "        return line\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.recursive_tree_print(self.leaves)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ab46d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(directory, experiment_name, naming_schema=None):\n",
    "    path = Path(directory)\n",
    "\n",
    "    dirs = [e for e in path.iterdir() if e.is_dir() and not str(e) == '.ipynb_checkpoints']\n",
    "    subdirs = {str(path): [e for e in path.iterdir() if e.is_dir()] for path in dirs}\n",
    "    \n",
    "    relevant_subdirs = subdirs[os.path.join(directory, experiment_name)]\n",
    "    relevant_subdirs.sort()\n",
    "    #result_filename = '*.pickle'\n",
    "    pickle_dirs = list()\n",
    "    for subdir in relevant_subdirs:\n",
    "        pickle_dirs.extend(sorted(subdir.glob(\"*.pickle\")))\n",
    "    results = []\n",
    "    if not naming_schema is None:\n",
    "        all_attributes = [extract_setting_from_name(subdir.name, naming_schema) for subdir in relevant_subdirs]    \n",
    "        for attributes, pick in zip(all_attributes, pickle_dirs):\n",
    "            try:\n",
    "                unpickled_stuff = unpickle(pick)\n",
    "                results.append({'attributes': attributes, 'results': unpickled_stuff})\n",
    "            except:\n",
    "                # Sometimes there were unknown issues with the pickle files, in those instances we re-ran training\n",
    "                print(\"Catastrophic failure\")\n",
    "    else:\n",
    "        for pick in pickle_dirs:\n",
    "            try:\n",
    "                unpickled_stuff = unpickle(pick)\n",
    "                results.append({'results': unpickled_stuff})\n",
    "            except:\n",
    "                # Sometimes there were unknown issues with the pickle files, in those instances we re-ran training\n",
    "                print(\"Catastrophic failure\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef7376c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_dict_get(data : dict, path : str):\n",
    "    \"\"\"\n",
    "    path a slash ('/') separated path down to \n",
    "    \"\"\"\n",
    "    temp = data.copy()\n",
    "    for entry in path.split(\"/\"):\n",
    "        # Catches leading '/' in tree printing\n",
    "        if entry == '':\n",
    "            continue\n",
    "        temp = temp[entry]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f41bc6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_values(d1 : dict, d2 : dict, path : str):\n",
    "    v1 = deep_dict_get(d1, path)\n",
    "    v2 = deep_dict_get(d2, path)\n",
    "    # Sanity check 1\n",
    "    if not type(v1) == type(v2):\n",
    "        return False\n",
    "    else:\n",
    "        # This can potentially cause errors when comparing lists of lists (or Tensors/Arrays)\n",
    "        return v1 == v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d833486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_common_root_list(root : str, values : list):\n",
    "    return [f\"{root}/{val}\" for val in values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed03ddf",
   "metadata": {},
   "source": [
    "# Main functions    \n",
    "What features do I need?    \n",
    "- ~~Show a structure tree of the results (i.e. experiment settings and result values)~~~\n",
    "- ~~Filtering by setting, given a key~~\n",
    "- ~~Filtering by values, given a key~~\n",
    "- Create selected statistics (mean/med/std/quartiles/...) for certain values/keys\n",
    "- Apply a function to certain values/keys and return the results (e.g. Eigendecomposition/Normalization/...)\n",
    "- ~~Group all entries that share settings/values~~\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb4593bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tree_structure(data, parent=None):\n",
    "    # Solved through recursively going deeper into the data structure and then returning the leafs if at the end\n",
    "\n",
    "    if parent is None and not len(data.keys()) == 1:\n",
    "        parent = Node(\"root\")\n",
    "    elif parent is None:\n",
    "        parent = Node(list(data.keys())[0])\n",
    "        data = data[list(data.keys())[0]]\n",
    "    \n",
    "    # Recursion condition\n",
    "    # If there are any dictionaries inside then go deeper\n",
    "    if not any([type(data[entry]) == dict for entry in data]):\n",
    "        for entry in data:\n",
    "            Node(entry, parent=parent) \n",
    "    else:\n",
    "        for entry in data:\n",
    "            if type(data[entry]) == dict:\n",
    "                branch = Node(entry, parent=parent)\n",
    "                generate_tree_structure(data[entry], parent=branch)\n",
    "            else:\n",
    "                Node(entry, parent=parent)\n",
    "    return parent\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da64394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by(list_of_data : list, path, value=None):\n",
    "    \"\"\"\n",
    "    value : If None, make subgroups of equal values. \n",
    "            Otherwise return a single group where value is matched\n",
    "    \"\"\"\n",
    "    grouped_data = {}\n",
    "\n",
    "    if not value is None:\n",
    "        grouped_data[f\"{path} = {value}\"] = [data for data in list_of_data if deep_dict_get(data, path) == value]\n",
    "    else:    \n",
    "        finished_values = list()\n",
    "        for data in list_of_data:\n",
    "            value = deep_dict_get(data, path)\n",
    "            grouped_data[f\"{path} = {value}\"].append(data)\n",
    "            #if not value in finished_values:\n",
    "            #    grouped_data[f\"{path} = value\"] = [data for data in list_of_data if deep_dict_get(data, path) == value]\n",
    "            #    finished_values.append(value)\n",
    "    return grouped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e29e1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_compare(d1, d2):\n",
    "    # Checking for empty list in d2, i.e. initial value\n",
    "    if not type(d1) == type(d2):\n",
    "        return False\n",
    "    return all((d1.get(k) == v for k, v in d2.items()))\n",
    "        \n",
    "\n",
    "# Could contain an alternative head as (list_of_data : list, paths : [list, dict], values : None) \n",
    "# where paths-values would require a 1-to-1 correspondence. \n",
    "# But this could quickly become error prone on the user side...\n",
    "def group_by_multiple(list_of_data : list, paths):\n",
    "    grouped_data = {}\n",
    "    # Grouping without values\n",
    "    if type(paths) == list:\n",
    "        finished_values = list()\n",
    "        for data in list_of_data:\n",
    "            paths_vals = {path : deep_dict_get(data, path) for path in paths}\n",
    "            # not any X <=> all not X\n",
    "            # i.e. only succeeds when this combination didn't exist before\n",
    "            if not any([dict_comapare(paths_vals, fin_val) for fin_val in finished_values]):\n",
    "                grouped_data[\" ; \".join([f\"{path} = {paths_vals[path]}\" for path in paths_vals])] = [data]\n",
    "            else:\n",
    "                grouped_data[\" ; \".join([f\"{path} = {paths_vals[path]}\" for path in paths_vals])].append(data)\n",
    "\n",
    "    # Grouping by path-value combinations\n",
    "    # Only returns the group where all those pairs are true\n",
    "    elif type(paths) == dict:\n",
    "        # The keys will contain the paths\n",
    "        # The values will be the corresponding expected values\n",
    "        # Yes, this could be a one-liner with a very neat nested list creation, \n",
    "        #  but I chose readability with temporary variables over it.\n",
    "        good_data = list()\n",
    "        for data in list_of_data:\n",
    "            if all([deep_dict_get(data, path) == paths[path] for path in paths]):\n",
    "                good_data.append(data)\n",
    "        grouped_data[\" ; \".join([f\"{path} = {paths[path]}\" for path in paths])] = good_data\n",
    "    return grouped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e065d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by(list_of_data : list, path : str, value):\n",
    "    filtered_data = list()\n",
    "    for data in list_of_data:\n",
    "        if deep_dict_get(data, path) == value:\n",
    "            filtered_data.append(data)\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "174730a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_value(list_of_data : list, path : str):\n",
    "    \"\"\"\n",
    "        returns a list of the target value from each data dict\n",
    "    \"\"\"\n",
    "    list_of_values = list()\n",
    "    for data in list_of_data:\n",
    "        list_of_values.append(deep_dict_get(data, path))\n",
    "    return list_of_values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d505fea3",
   "metadata": {},
   "source": [
    "# Pseudocode blocks\n",
    "\n",
    "\n",
    "def calc_mean(data):\n",
    "    return mean(data)\n",
    "\n",
    "def calc_std(data):\n",
    "    return std(data)\n",
    "\n",
    "\n",
    "def calc_statistics(data, statistics):\n",
    "    if type(statistics) == list:\n",
    "        result dictionary\n",
    "        for statistic in statistics:\n",
    "            result_dict[statistic] = call statistic\n",
    "        return result_dict\n",
    "    else:\n",
    "        reutrn call statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b944501",
   "metadata": {},
   "source": [
    "# Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b730f878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Node('/results/attributes'),\n",
      " Node('/results/attributes/eval_START'),\n",
      " Node('/results/attributes/eval_END'),\n",
      " Node('/results/attributes/eval_COUNT'),\n",
      " Node('/results/attributes/optimizer'),\n",
      " Node('/results/attributes/train_iters'),\n",
      " Node('/results/attributes/LR'),\n",
      " Node('/results/attributes/BFGS'),\n",
      " Node('/results/attributes/data_gen'),\n",
      " Node('/results/Laplace'),\n",
      " Node('/results/Laplace/SIN*RBF'),\n",
      " Node('/results/Laplace/SIN*RBF/parameter_punishment'),\n",
      " Node('/results/Laplace/SIN*RBF/loss'),\n",
      " Node('/results/Laplace/SIN*RBF/details'),\n",
      " Node('/results/Laplace/SIN*RBF/details/MLL'),\n",
      " Node('/results/Laplace/SIN*RBF/details/parameter list'),\n",
      " Node('/results/Laplace/SIN*RBF/details/parameter values'),\n",
      " Node('/results/Laplace/SIN*RBF/details/corrected Hessian'),\n",
      " Node('/results/Laplace/SIN*RBF/details/diag(constructed eigvals)'),\n",
      " Node('/results/Laplace/SIN*RBF/details/original symmetrized Hessian'),\n",
      " Node('/results/Laplace/SIN*RBF/details/prior mean'),\n",
      " Node('/results/Laplace/SIN*RBF/details/diag(prior var)'),\n",
      " Node('/results/Laplace/SIN*RBF/details/likelihood approximation'),\n",
      " Node('/results/Laplace/SIN*RBF/details/Derivative time'),\n",
      " Node('/results/Laplace/SIN*RBF/details/Approximation time'),\n",
      " Node('/results/Laplace/SIN*RBF/details/Correction time'),\n",
      " Node('/results/Laplace/SIN*RBF/details/Prior generation time'),\n",
      " Node('/results/Laplace/SIN*RBF/details/Total time'),\n",
      " Node('/results/Laplace/C*C*RBF'),\n",
      " Node('/results/Laplace/C*C*RBF/parameter_punishment'),\n",
      " Node('/results/Laplace/C*C*RBF/loss'),\n",
      " Node('/results/Laplace/C*C*RBF/details'),\n",
      " Node('/results/Laplace/C*C*RBF/details/MLL'),\n",
      " Node('/results/Laplace/C*C*RBF/details/parameter list'),\n",
      " Node('/results/Laplace/C*C*RBF/details/parameter values'),\n",
      " Node('/results/Laplace/C*C*RBF/details/corrected Hessian'),\n",
      " Node('/results/Laplace/C*C*RBF/details/diag(constructed eigvals)'),\n",
      " Node('/results/Laplace/C*C*RBF/details/original symmetrized Hessian'),\n",
      " Node('/results/Laplace/C*C*RBF/details/prior mean'),\n",
      " Node('/results/Laplace/C*C*RBF/details/diag(prior var)'),\n",
      " Node('/results/Laplace/C*C*RBF/details/likelihood approximation'),\n",
      " Node('/results/Laplace/C*C*RBF/details/Derivative time'),\n",
      " Node('/results/Laplace/C*C*RBF/details/Approximation time'),\n",
      " Node('/results/Laplace/C*C*RBF/details/Correction time'),\n",
      " Node('/results/Laplace/C*C*RBF/details/Prior generation time'),\n",
      " Node('/results/Laplace/C*C*RBF/details/Total time'),\n",
      " Node('/results/Laplace/C*RBF'),\n",
      " Node('/results/Laplace/C*RBF/parameter_punishment'),\n",
      " Node('/results/Laplace/C*RBF/loss'),\n",
      " Node('/results/Laplace/C*RBF/details'),\n",
      " Node('/results/Laplace/C*RBF/details/MLL'),\n",
      " Node('/results/Laplace/C*RBF/details/parameter list'),\n",
      " Node('/results/Laplace/C*RBF/details/parameter values'),\n",
      " Node('/results/Laplace/C*RBF/details/corrected Hessian'),\n",
      " Node('/results/Laplace/C*RBF/details/diag(constructed eigvals)'),\n",
      " Node('/results/Laplace/C*RBF/details/original symmetrized Hessian'),\n",
      " Node('/results/Laplace/C*RBF/details/prior mean'),\n",
      " Node('/results/Laplace/C*RBF/details/diag(prior var)'),\n",
      " Node('/results/Laplace/C*RBF/details/likelihood approximation'),\n",
      " Node('/results/Laplace/C*RBF/details/Derivative time'),\n",
      " Node('/results/Laplace/C*RBF/details/Approximation time'),\n",
      " Node('/results/Laplace/C*RBF/details/Correction time'),\n",
      " Node('/results/Laplace/C*RBF/details/Prior generation time'),\n",
      " Node('/results/Laplace/C*RBF/details/Total time'),\n",
      " Node('/results/Laplace/4C*SIN'),\n",
      " Node('/results/Laplace/4C*SIN/parameter_punishment'),\n",
      " Node('/results/Laplace/4C*SIN/loss'),\n",
      " Node('/results/Laplace/4C*SIN/details'),\n",
      " Node('/results/Laplace/4C*SIN/details/MLL'),\n",
      " Node('/results/Laplace/4C*SIN/details/parameter list'),\n",
      " Node('/results/Laplace/4C*SIN/details/parameter values'),\n",
      " Node('/results/Laplace/4C*SIN/details/corrected Hessian'),\n",
      " Node('/results/Laplace/4C*SIN/details/diag(constructed eigvals)'),\n",
      " Node('/results/Laplace/4C*SIN/details/original symmetrized Hessian'),\n",
      " Node('/results/Laplace/4C*SIN/details/prior mean'),\n",
      " Node('/results/Laplace/4C*SIN/details/diag(prior var)'),\n",
      " Node('/results/Laplace/4C*SIN/details/likelihood approximation'),\n",
      " Node('/results/Laplace/4C*SIN/details/Derivative time'),\n",
      " Node('/results/Laplace/4C*SIN/details/Approximation time'),\n",
      " Node('/results/Laplace/4C*SIN/details/Correction time'),\n",
      " Node('/results/Laplace/4C*SIN/details/Prior generation time'),\n",
      " Node('/results/Laplace/4C*SIN/details/Total time'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN + C*SIN'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN + C*SIN/parameter_punishment'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN + C*SIN/loss'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN + C*SIN/details'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN + C*SIN/details/MLL'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN + C*SIN/details/parameter list'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN + C*SIN/details/parameter values'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN + C*SIN/details/corrected Hessian'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN + C*SIN/details/diag(constructed eigvals)'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN + C*SIN/details/original symmetrized Hessian'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN + C*SIN/details/prior mean'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN + C*SIN/details/diag(prior var)'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN + C*SIN/details/likelihood approximation'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN + C*SIN/details/Derivative time'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN + C*SIN/details/Approximation time'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN + C*SIN/details/Correction time'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN + C*SIN/details/Prior generation time'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN + C*SIN/details/Total time'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN/parameter_punishment'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN/loss'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN/details'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN/details/MLL'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN/details/parameter list'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN/details/parameter values'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN/details/corrected Hessian'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN/details/diag(constructed eigvals)'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN/details/original symmetrized Hessian'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN/details/prior mean'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN/details/diag(prior var)'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN/details/likelihood approximation'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN/details/Derivative time'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN/details/Approximation time'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN/details/Correction time'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN/details/Prior generation time'),\n",
      " Node('/results/Laplace/C*SIN + C*SIN/details/Total time'),\n",
      " Node('/results/Laplace/C*SIN'),\n",
      " Node('/results/Laplace/C*SIN/parameter_punishment'),\n",
      " Node('/results/Laplace/C*SIN/loss'),\n",
      " Node('/results/Laplace/C*SIN/details'),\n",
      " Node('/results/Laplace/C*SIN/details/MLL'),\n",
      " Node('/results/Laplace/C*SIN/details/parameter list'),\n",
      " Node('/results/Laplace/C*SIN/details/parameter values'),\n",
      " Node('/results/Laplace/C*SIN/details/corrected Hessian'),\n",
      " Node('/results/Laplace/C*SIN/details/diag(constructed eigvals)'),\n",
      " Node('/results/Laplace/C*SIN/details/original symmetrized Hessian'),\n",
      " Node('/results/Laplace/C*SIN/details/prior mean'),\n",
      " Node('/results/Laplace/C*SIN/details/diag(prior var)'),\n",
      " Node('/results/Laplace/C*SIN/details/likelihood approximation'),\n",
      " Node('/results/Laplace/C*SIN/details/Derivative time'),\n",
      " Node('/results/Laplace/C*SIN/details/Approximation time'),\n",
      " Node('/results/Laplace/C*SIN/details/Correction time'),\n",
      " Node('/results/Laplace/C*SIN/details/Prior generation time'),\n",
      " Node('/results/Laplace/C*SIN/details/Total time'))\n",
      "############################\n",
      "4PER\n",
      "\n",
      "----\n",
      "4C*SIN:\n",
      "\n",
      "Laplace\t - \ttensor([[157.8948]], requires_grad=True)\n",
      "\n",
      "----\n",
      "C*C*RBF:\n",
      "\n",
      "Laplace\t - \ttensor([[-148.3393]], requires_grad=True)\n",
      "\n",
      "----\n",
      "C*RBF:\n",
      "\n",
      "Laplace\t - \ttensor([[-172.5380]], requires_grad=True)\n",
      "\n",
      "----\n",
      "C*SIN:\n",
      "\n",
      "Laplace\t - \ttensor([[-89.1981]], requires_grad=True)\n",
      "\n",
      "----\n",
      "C*SIN + C*SIN:\n",
      "\n",
      "Laplace\t - \ttensor([[179.1551]], requires_grad=True)\n",
      "\n",
      "----\n",
      "C*SIN + C*SIN + C*SIN:\n",
      "\n",
      "Laplace\t - \ttensor([[-168.9682]], requires_grad=True)\n",
      "\n",
      "----\n",
      "SIN*RBF:\n",
      "\n",
      "Laplace\t - \ttensor([[-50.4099]], requires_grad=True)\n",
      "############################\n",
      "PER\n",
      "\n",
      "----\n",
      "4C*SIN:\n",
      "\n",
      "Laplace\t - \ttensor([[232.0750]], requires_grad=True)\n",
      "\n",
      "----\n",
      "C*C*RBF:\n",
      "\n",
      "Laplace\t - \ttensor([[-148.3395]], requires_grad=True)\n",
      "\n",
      "----\n",
      "C*RBF:\n",
      "\n",
      "Laplace\t - \ttensor([[-149.8078]], requires_grad=True)\n",
      "\n",
      "----\n",
      "C*SIN:\n",
      "\n",
      "Laplace\t - \ttensor([[135.2880]], requires_grad=True)\n",
      "\n",
      "----\n",
      "C*SIN + C*SIN:\n",
      "\n",
      "Laplace\t - \ttensor([[253.3781]], requires_grad=True)\n",
      "\n",
      "----\n",
      "C*SIN + C*SIN + C*SIN:\n",
      "\n",
      "Laplace\t - \ttensor([[239.8567]], requires_grad=True)\n",
      "\n",
      "----\n",
      "SIN*RBF:\n",
      "\n",
      "Laplace\t - \ttensor([[233.9989]], requires_grad=True)\n",
      "############################\n",
      "RBF_PER\n",
      "\n",
      "----\n",
      "4C*SIN:\n",
      "\n",
      "Laplace\t - \ttensor([[-126.1914]], requires_grad=True)\n",
      "\n",
      "----\n",
      "C*C*RBF:\n",
      "\n",
      "Laplace\t - \ttensor([[-148.3631]], requires_grad=True)\n",
      "\n",
      "----\n",
      "C*RBF:\n",
      "\n",
      "Laplace\t - \ttensor([[-149.8896]], requires_grad=True)\n",
      "\n",
      "----\n",
      "C*SIN:\n",
      "\n",
      "Laplace\t - \ttensor([[-120.6778]], requires_grad=True)\n",
      "\n",
      "----\n",
      "C*SIN + C*SIN:\n",
      "\n",
      "Laplace\t - \ttensor([[-123.0363]], requires_grad=True)\n",
      "\n",
      "----\n",
      "C*SIN + C*SIN + C*SIN:\n",
      "\n",
      "Laplace\t - \ttensor([[-125.7866]], requires_grad=True)\n",
      "\n",
      "----\n",
      "SIN*RBF:\n",
      "\n",
      "Laplace\t - \ttensor([[95.1895]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#naming_schema = [\"Metric\", \"Kernel_search\", \"train_data_ratio\", \"Data_kernel\", \"weights\", \"Variance_list\", \"eval_START\", \"eval_END\", \"eval_COUNT\", \"optimizer\", \"train_iterations\", \"LR\", \"Noise\", \"Data_scaling\", \"BFGS\"]\n",
    "all_results = load_results('results', \"hardcoded\")\n",
    "#pprint.pprint(all_results)\n",
    "result_tree = generate_tree_structure(all_results[0]).descendants\n",
    "pprint.pprint(result_tree)\n",
    "\n",
    "\n",
    "# data - kernel assignment : RBF_PER = SIN*RBF; 4PER = 4C*SIN; PER = C*SIN\n",
    "# Perform for each main dictionary: Iterate over kernels -> Look for the lowest(highest?) loss, \n",
    "\n",
    "\n",
    "for main_dict in all_results:\n",
    "    print(\"############################\")\n",
    "    print(main_dict[\"results\"][\"attributes\"][\"data_gen\"])\n",
    "    for model_kernel in ['4C*SIN','C*C*RBF','C*RBF','C*SIN','C*SIN + C*SIN','C*SIN + C*SIN + C*SIN','SIN*RBF']:\n",
    "        print(\"\\n----\")\n",
    "        print(f\"{model_kernel}:\\n\")\n",
    "        for metric in [\"Laplace\"]:#, \"MC\", \"MLL\", \"AIC\"]:\n",
    "            print(f\"{metric}\\t - \\t{main_dict['results'][metric][model_kernel]['loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6660c3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Approximation time': 0.0004425048828125,\n",
      " 'Correction time': 0.0016541481018066406,\n",
      " 'Derivative time': 0.03189587593078613,\n",
      " 'MLL': tensor(227.9842, requires_grad=True),\n",
      " 'Prior generation time': 0.00019431114196777344,\n",
      " 'Total time': 0.034353017807006836,\n",
      " 'corrected Hessian': tensor([[-6.2433e-01,  2.6383e-03, -5.9260e-03,  6.1808e-02,  1.1424e-02,\n",
      "         -4.4135e-03,  6.1808e-02, -2.0227e-03, -3.8999e-03,  6.1808e-02,\n",
      "          1.9806e-03, -3.8923e-03,  6.1808e-02],\n",
      "        [ 2.6383e-03, -1.7003e+00,  3.7035e+00, -1.3297e+00, -1.5400e+00,\n",
      "          2.5947e+00, -6.4673e+00, -4.0572e-01,  3.3184e+00, -4.3488e+00,\n",
      "         -4.8372e-01,  3.4279e+00,  2.5355e+00],\n",
      "        [-5.9260e-03,  3.7035e+00, -3.5875e+01,  6.2721e+01,  1.4987e+00,\n",
      "         -1.5118e+00, -6.9491e+00,  2.4215e+00, -1.1790e+01,  7.2209e+00,\n",
      "          2.4931e+00, -1.4299e+01, -1.4942e+01],\n",
      "        [ 6.1808e-02, -1.3297e+00,  6.2721e+01, -7.5123e+07, -8.3576e+00,\n",
      "         -9.8405e+00, -1.9631e+06, -4.8591e-01,  1.3051e+00, -8.6151e+06,\n",
      "         -6.3114e+00, -1.5010e+01,  9.8266e+06],\n",
      "        [ 1.1424e-02, -1.5400e+00,  1.4987e+00, -8.3576e+00, -1.1245e+01,\n",
      "          2.1504e+00, -2.5676e+00,  1.3107e+00,  1.0776e-01, -1.4597e+00,\n",
      "          1.0098e+00, -1.8636e-02, -8.9979e-01],\n",
      "        [-4.4135e-03,  2.5947e+00, -1.5118e+00, -9.8405e+00,  2.1504e+00,\n",
      "         -4.5860e+01,  6.2310e+01,  3.1822e+00, -1.0391e+01, -6.2384e+00,\n",
      "          2.5087e+00, -5.9133e+00,  1.8201e+00],\n",
      "        [ 6.1808e-02, -6.4673e+00, -6.9491e+00, -1.9631e+06, -2.5676e+00,\n",
      "          6.2310e+01, -7.4253e+07, -6.5131e+00, -4.5526e+00, -9.6765e+05,\n",
      "         -4.4621e+00, -6.4331e+00,  1.3094e+06],\n",
      "        [-2.0227e-03, -4.0572e-01,  2.4215e+00, -4.8591e-01,  1.3107e+00,\n",
      "          3.1822e+00, -6.5131e+00, -1.4811e+00,  3.2270e+00,  1.9548e+00,\n",
      "          5.3222e-01,  3.2300e+00, -8.2405e+00],\n",
      "        [-3.8999e-03,  3.3184e+00, -1.1790e+01,  1.3051e+00,  1.0776e-01,\n",
      "         -1.0391e+01, -4.5526e+00,  3.2270e+00, -2.0673e+01,  5.2197e+01,\n",
      "          2.9763e+00, -2.1327e+01, -8.9845e-01],\n",
      "        [ 6.1808e-02, -4.3488e+00,  7.2209e+00, -8.6151e+06, -1.4597e+00,\n",
      "         -6.2384e+00, -9.6765e+05,  1.9548e+00,  5.2197e+01, -6.2410e+07,\n",
      "         -1.8442e+00,  8.9807e-02, -3.8813e+06],\n",
      "        [ 1.9806e-03, -4.8372e-01,  2.4931e+00, -6.3114e+00,  1.0098e+00,\n",
      "          2.5087e+00, -4.4621e+00,  5.3222e-01,  2.9763e+00, -1.8442e+00,\n",
      "         -2.6634e+00,  2.9202e+00, -6.6706e-01],\n",
      "        [-3.8923e-03,  3.4279e+00, -1.4299e+01, -1.5010e+01, -1.8636e-02,\n",
      "         -5.9133e+00, -6.4331e+00,  3.2300e+00, -2.1327e+01,  8.9810e-02,\n",
      "          2.9202e+00, -2.2665e+01,  6.9404e+01],\n",
      "        [ 6.1808e-02,  2.5355e+00, -1.4942e+01,  9.8266e+06, -8.9979e-01,\n",
      "          1.8201e+00,  1.3094e+06, -8.2405e+00, -8.9845e-01, -3.8813e+06,\n",
      "         -6.6706e-01,  6.9404e+01, -8.3129e+07]]),\n",
      " 'diag(constructed eigvals)': tensor([-6.2432e-01, -7.5874e+07, -7.3013e+07, -6.5632e+01, -2.9982e+00,\n",
      "        -1.1363e+00, -7.3014e+07, -7.3013e+07, -2.0081e+01, -8.6094e+00,\n",
      "        -2.9982e+00, -2.1319e+01, -2.1319e+01]),\n",
      " 'diag(prior var)': tensor([3.2660, 2.4480, 2.6360, 0.9020, 2.4480, 2.6360, 0.9020, 2.4480, 2.6360,\n",
      "        0.9020, 2.4480, 2.6360, 0.9020]),\n",
      " 'likelihood approximation': tensor([[157.8948]], requires_grad=True),\n",
      " 'original symmetrized Hessian': tensor([[-1.2473e-01, -2.5325e-03, -5.5473e-03,  6.1808e-02, -2.5325e-03,\n",
      "         -5.5473e-03,  6.1808e-02, -2.5325e-03, -5.5473e-03,  6.1808e-02,\n",
      "         -2.5325e-03, -5.5473e-03,  6.1808e-02],\n",
      "        [-2.5325e-03, -2.9752e-01,  3.3470e+00, -4.6400e+00, -9.4008e-01,\n",
      "          2.7890e+00, -2.9593e+00, -9.4008e-01,  2.7890e+00, -2.9593e+00,\n",
      "         -9.4008e-01,  2.7890e+00, -2.9593e+00],\n",
      "        [-5.5473e-03,  3.3470e+00, -3.1854e+01,  6.1085e+01,  2.7890e+00,\n",
      "         -1.0577e+01, -4.4386e+00,  2.7890e+00, -1.0577e+01, -4.4386e+00,\n",
      "          2.7890e+00, -1.0577e+01, -4.4386e+00],\n",
      "        [ 6.1808e-02, -4.6400e+00,  6.1085e+01, -7.3729e+07, -2.9593e+00,\n",
      "         -4.4386e+00, -7.1520e+05, -2.9593e+00, -4.4386e+00, -7.1520e+05,\n",
      "         -2.9593e+00, -4.4386e+00, -7.1520e+05],\n",
      "        [-2.5325e-03, -9.4008e-01,  2.7890e+00, -2.9593e+00, -2.9752e-01,\n",
      "          3.3470e+00, -4.6400e+00, -9.4008e-01,  2.7890e+00, -2.9593e+00,\n",
      "         -9.4008e-01,  2.7890e+00, -2.9593e+00],\n",
      "        [-5.5473e-03,  2.7890e+00, -1.0577e+01, -4.4386e+00,  3.3470e+00,\n",
      "         -3.1854e+01,  6.1085e+01,  2.7890e+00, -1.0577e+01, -4.4386e+00,\n",
      "          2.7890e+00, -1.0577e+01, -4.4386e+00],\n",
      "        [ 6.1808e-02, -2.9593e+00, -4.4386e+00, -7.1520e+05, -4.6400e+00,\n",
      "          6.1085e+01, -7.3729e+07, -2.9593e+00, -4.4386e+00, -7.1520e+05,\n",
      "         -2.9593e+00, -4.4386e+00, -7.1520e+05],\n",
      "        [-2.5325e-03, -9.4008e-01,  2.7890e+00, -2.9593e+00, -9.4008e-01,\n",
      "          2.7890e+00, -2.9593e+00, -2.9752e-01,  3.3470e+00, -4.6400e+00,\n",
      "         -9.4008e-01,  2.7890e+00, -2.9593e+00],\n",
      "        [-5.5473e-03,  2.7890e+00, -1.0577e+01, -4.4386e+00,  2.7890e+00,\n",
      "         -1.0577e+01, -4.4386e+00,  3.3470e+00, -3.1854e+01,  6.1085e+01,\n",
      "          2.7890e+00, -1.0577e+01, -4.4386e+00],\n",
      "        [ 6.1808e-02, -2.9593e+00, -4.4386e+00, -7.1520e+05, -2.9593e+00,\n",
      "         -4.4386e+00, -7.1520e+05, -4.6400e+00,  6.1085e+01, -7.3729e+07,\n",
      "         -2.9593e+00, -4.4386e+00, -7.1520e+05],\n",
      "        [-2.5325e-03, -9.4008e-01,  2.7890e+00, -2.9593e+00, -9.4008e-01,\n",
      "          2.7890e+00, -2.9593e+00, -9.4008e-01,  2.7890e+00, -2.9593e+00,\n",
      "         -2.9752e-01,  3.3470e+00, -4.6400e+00],\n",
      "        [-5.5473e-03,  2.7890e+00, -1.0577e+01, -4.4386e+00,  2.7890e+00,\n",
      "         -1.0577e+01, -4.4386e+00,  2.7890e+00, -1.0577e+01, -4.4386e+00,\n",
      "          3.3470e+00, -3.1854e+01,  6.1085e+01],\n",
      "        [ 6.1808e-02, -2.9593e+00, -4.4386e+00, -7.1520e+05, -2.9593e+00,\n",
      "         -4.4386e+00, -7.1520e+05, -2.9593e+00, -4.4386e+00, -7.1520e+05,\n",
      "         -4.6400e+00,  6.1085e+01, -7.3729e+07]]),\n",
      " 'parameter list': ['likelihood.noise_covar.raw_noise',\n",
      "                    'covar_module.kernels.0.raw_outputscale',\n",
      "                    'covar_module.kernels.0.base_kernel.raw_lengthscale',\n",
      "                    'covar_module.kernels.0.base_kernel.raw_period_length',\n",
      "                    'covar_module.kernels.1.raw_outputscale',\n",
      "                    'covar_module.kernels.1.base_kernel.raw_lengthscale',\n",
      "                    'covar_module.kernels.1.base_kernel.raw_period_length',\n",
      "                    'covar_module.kernels.2.raw_outputscale',\n",
      "                    'covar_module.kernels.2.base_kernel.raw_lengthscale',\n",
      "                    'covar_module.kernels.2.base_kernel.raw_period_length',\n",
      "                    'covar_module.kernels.3.raw_outputscale',\n",
      "                    'covar_module.kernels.3.base_kernel.raw_lengthscale',\n",
      "                    'covar_module.kernels.3.base_kernel.raw_period_length'],\n",
      " 'parameter values': tensor([[-14.8528],\n",
      "        [ -1.4957],\n",
      "        [ -2.2924],\n",
      "        [ -0.0214],\n",
      "        [ -1.4957],\n",
      "        [ -2.2924],\n",
      "        [ -0.0214],\n",
      "        [ -1.4957],\n",
      "        [ -2.2924],\n",
      "        [ -0.0214],\n",
      "        [ -1.4957],\n",
      "        [ -2.2924],\n",
      "        [ -0.0214]]),\n",
      " 'prior mean': tensor([[-1.7920],\n",
      "        [-2.1630],\n",
      "        [ 0.3380],\n",
      "        [ 0.2840],\n",
      "        [-2.1630],\n",
      "        [ 0.3380],\n",
      "        [ 0.2840],\n",
      "        [-2.1630],\n",
      "        [ 0.3380],\n",
      "        [ 0.2840],\n",
      "        [-2.1630],\n",
      "        [ 0.3380],\n",
      "        [ 0.2840]])}\n",
      "tensor([[-46.7252]])\n",
      "tensor([[243.1192]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#all_results[0][\"results\"][\"attributes\"][\"data_gen\"]\n",
    "pprint.pprint(all_results[0][\"results\"][\"Laplace\"][\"4C*SIN\"][\"details\"])\n",
    "MLL = all_results[0][\"results\"][\"Laplace\"][\"4C*SIN\"][\"details\"][\"MLL\"]\n",
    "H = all_results[0][\"results\"][\"Laplace\"][\"4C*SIN\"][\"details\"][\"corrected Hessian\"]\n",
    "S = torch.diag(all_results[0][\"results\"][\"Laplace\"][\"4C*SIN\"][\"details\"][\"diag(prior var)\"])\n",
    "t_mu = all_results[0][\"results\"][\"Laplace\"][\"4C*SIN\"][\"details\"][\"prior mean\"]\n",
    "t_0 = all_results[0][\"results\"][\"Laplace\"][\"4C*SIN\"][\"details\"][\"parameter values\"]\n",
    "\n",
    "diff = t_mu - t_0\n",
    "mid_term = (S.inverse() - H).inverse()\n",
    "matmuls = diff.t() @ S.inverse() @ mid_term @ H @ diff\n",
    "print(matmuls)\n",
    "#print(torch.log(S.det()))\n",
    "print(MLL - 0.5*torch.log(S.det()) - 0.5*torch.log(mid_term.det()) + 0.5* matmuls)\n",
    "#pprint.pprint(list(zip(all_results[0][\"results\"][\"Laplace\"][\"4C*SIN\"][\"details\"]['parameter list'], all_results[0][\"results\"][\"Laplace\"][\"4C*SIN\"][\"details\"]['parameter values'])))\n",
    "\n",
    "#pprint.pprint(torch.linalg.eig(all_results[0][\"results\"][\"Laplace\"][\"4C*SIN\"][\"details\"][\"corrected Hessian\"]))\n",
    "#pprint.pprint(torch.linalg.eig(all_results[0][\"results\"][\"Laplace\"][\"4C*SIN\"][\"details\"][\"original symmetrized Hessian\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd71d8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#naming_schema = [\"Metric\", \"Kernel_search\", \"train_data_ratio\", \"Data_kernel\", \"weights\", \"Variance_list\", \"eval_START\", \"eval_END\", \"eval_COUNT\", \"optimizer\", \"train_iterations\", \"LR\", \"Noise\", \"Data_scaling\", \"BFGS\"]\n",
    "all_results = load_results('results', \"Laplace\")\n",
    "print(len(all_results))\n",
    "result_tree = generate_tree_structure(all_results[0]).descendants\n",
    "pprint.pprint(result_tree)\n",
    "\n",
    "print(filter_value(all_results, '/results/results/final model'))\n",
    "\n",
    "#########\n",
    "\"\"\"\n",
    "    Looking at the final models that were found and the ratio of exactly the correct one\n",
    "\"\"\"\n",
    "#########\n",
    "print(\"\\n########## Laplace ##########\\n\")\n",
    "all_final_models = filter_value(all_results, '/results/results/final model')\n",
    "winners = group_by(all_results, 'results/results/final model', value='(c * PER)')['results/results/final model = (c * PER)']\n",
    "print(f\"Percentage of exactly correct model: {len(winners)/len(all_final_models)*100}\")\n",
    "print(f\"Percentage of correct component: {np.sum(['PER' in m for m in all_final_models])}\")\n",
    "print(\"\\n##############\\n\")\n",
    "Laplace_runtimes = filter_value(all_results, '/results/results/details/Total time')\n",
    "#training_runtimes = filter_value(all_results, '/results/results/Training time')\n",
    "#KS_runtimes = filter_value(all_results, '/results/results/Kernel search time')\n",
    "print(f\"Average Laplace runtime: {np.mean(Laplace_runtimes)}\")\n",
    "#print(f\"Average Laplace runtime: {np.mean(KS_runtimes)}\")\n",
    "\n",
    "print(\"\\n#############################\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d2000be",
   "metadata": {},
   "source": [
    "#naming_schema = [\"Metric\", \"Kernel_search\", \"train_data_ratio\", \"Data_kernel\", \"weights\", \"Variance_list\", \"eval_START\", \"eval_END\", \"eval_COUNT\", \"optimizer\", \"train_iterations\", \"LR\", \"Noise\", \"Data_scaling\", \"BFGS\"]\n",
    "all_results = load_results('results', \"MC\")\n",
    "result_tree = generate_tree_structure(all_results[0]).descendants\n",
    "pprint.pprint(result_tree)\n",
    "\n",
    "\n",
    "#########\n",
    "\"\"\"\n",
    "    Looking at the final models that were found and the ratio of exactly the correct one\n",
    "\"\"\"\n",
    "#########\n",
    "print(\"\\n########## MCMC ##########\\n\")\n",
    "all_final_models = filter_value(all_results, '/results/results/final model')\n",
    "winners = group_by(all_results, 'results/results/final model', value='(c * PER)')['results/results/final model = (c * PER)']\n",
    "print(f\"Percentage of exactly correct model: {len(winners)/len(all_final_models)*100}\")\n",
    "print(f\"Percentage of correct component: {np.sum(['PER' in m for m in all_final_models])}\")\n",
    "print(\"\\n#############################\")\n",
    "\n",
    "filter_value(all_results, '/results/results/details/Sampling time')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931e5497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379ead81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771c1a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
