{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a20b588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpFunctions import get_string_representation_of_kernel as gsr, clean_kernel_expression, print_formatted_hyperparameters\n",
    "import torch\n",
    "import gpytorch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1eb8b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, kernel_text=\"RBF\", weights=None):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "\n",
    "        if kernel_text == \"RBF\":\n",
    "            self.covar_module = gpytorch.kernels.RBFKernel()\n",
    "        elif kernel_text == \"SIN\":\n",
    "            self.covar_module = gpytorch.kernels.PeriodicKernel()\n",
    "        elif kernel_text == \"SIN+RBF\":\n",
    "            if weights is None:\n",
    "                self.covar_module = gpytorch.kernels.PeriodicKernel() + gpytorch.kernels.RBFKernel()\n",
    "            else:\n",
    "                self.covar_module = weights[0]*gpytorch.kernels.PeriodicKernel() + weights[1]*gpytorch.kernels.RBFKernel()\n",
    "        elif kernel_text == \"SIN*RBF\":\n",
    "            self.covar_module = gpytorch.kernels.PeriodicKernel() * gpytorch.kernels.RBFKernel()\n",
    "        elif kernel_text == \"SIN*LIN\":\n",
    "            self.covar_module = gpytorch.kernels.PeriodicKernel() * gpytorch.kernels.LinearKernel()\n",
    "        elif kernel_text == \"absurd\":\n",
    "            self.covar_module = gpytorch.kernels.RBFKernel() * ((gpytorch.kernels.PeriodicKernel() * gpytorch.kernels.LinearKernel()) + (gpytorch.kernels.PeriodicKernel() * gpytorch.kernels.LinearKernel()))\n",
    "\n",
    "            \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1171e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MyGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ZeroMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.PeriodicKernel()) + gpytorch.kernels.ScaleKernel(gpytorch.kernels.PeriodicKernel())\n",
    "          \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1ae9ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernels_in_kernel_expression(kernel_expression):\n",
    "    \"\"\"\n",
    "    returns list of all base kernels in a kernel expression\n",
    "    \"\"\"\n",
    "    if kernel_expression == None:\n",
    "        return []\n",
    "    if hasattr(kernel_expression, \"kernels\"):\n",
    "        ret = list()\n",
    "        for kernel in kernel_expression.kernels:\n",
    "            ret.extend(get_kernels_in_kernel_expression(kernel))\n",
    "        return ret\n",
    "    elif kernel_expression._get_name() == \"ScaleKernel\":\n",
    "        return get_kernels_in_kernel_expression(kernel_expression.base_kernel)\n",
    "    elif kernel_expression._get_name() == \"GridKernel\":\n",
    "        return get_kernels_in_kernel_expression(kernel_expression.base_kernel)\n",
    "    else:\n",
    "        return [kernel_expression]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9d5fd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/sage/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/sage/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-05 to the diagonal\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/sage/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-04 to the diagonal\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/sage/lib/python3.9/site-packages/linear_operator/operators/_linear_operator.py:2014: NumericalWarning: Runtime Error when computing Cholesky decomposition: Matrix not positive definite after repeatedly adding jitter up to 1.0e-04.. Using symeig method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# training data for model initialization (e.g. 1 point with x=0, y=0) ; this makes initializing the model easier\n",
    "prior_x = torch.linspace(0,1,1)\n",
    "prior_y = prior_x\n",
    "# initialize likelihood and model\n",
    "data_likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "data_model = ExactGPModel(prior_x, prior_y, data_likelihood, kernel_text=\"SIN\")\n",
    "observations_x = torch.linspace(-10, 10, 200)\n",
    "# Get into evaluation (predictive posterior) mode\n",
    "data_model.eval()\n",
    "data_likelihood.eval()\n",
    "\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.prior_mode(True):\n",
    "    observed_pred_prior = data_likelihood(data_model(observations_x))\n",
    "    f_preds = data_model(observations_x)\n",
    "    mean_prior = observed_pred_prior.mean\n",
    "    lower_prior, upper_prior = observed_pred_prior.confidence_region()\n",
    "\n",
    "f_mean = f_preds.mean\n",
    "f_var = f_preds.variance\n",
    "f_covar = f_preds.covariance_matrix\n",
    "observations_y = f_preds.sample()           # samples from the model\n",
    "\n",
    "\n",
    "X = observations_x[int((1-0.5)*0.5*200):int((1+0.5)*0.5*200)]\n",
    "Y = observations_y[int((1-0.5)*0.5*200):int((1+0.5)*0.5*200)]\n",
    "\n",
    "#X = (X-X.mean())/X.std()\n",
    "#Y = (Y-Y.mean())/Y.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2a9b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = MyGPModel(X, Y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4713dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "limits = {\"RBFKernel\": {\"lengthscale\": [1e-4,1]},\n",
    "          \"LinearKernel\": {\"variance\": [1e-4,1]},\n",
    "          \"PeriodicKernel\": {\"lengthscale\": [1e-4,10],\n",
    "                             \"period_length\": [1e-4,10]},\n",
    "          \"ScaleKernel\": {\"outputscale\": [1e-4,100]},\n",
    "          \"WhiteNoiseKernel\": {'lengthscale': [1e-4,1]},\n",
    "          \"CosineKernel\": {\"period_length\": [1e-4,10]},\n",
    "          \"Noise\": [1e-4,2e-3],\n",
    "          \"Mean\": [0.0,1.0]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06e7eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_repeats = 1000\n",
    "training_iter = 100\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "noise_list = list()\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "for j in range(random_repeats):\n",
    "    #print(list(model.named_parameters()))\n",
    "    #print(\"==============\")\n",
    "    try:\n",
    "        for i in range(training_iter):\n",
    "            # Zero gradients from previous iteration\n",
    "            optimizer.zero_grad()\n",
    "            # Output from model\n",
    "            output = model(X)\n",
    "            # Calc loss and backprop gradients\n",
    "            loss = -mll(output, Y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        noise_list.append(likelihood.noise_covar.noise.item())\n",
    "        #likelihood.noise_covar.noise = torch.rand(1) * (limits[\"Noise\"][1] - limits[\"Noise\"][0]) + limits[\"Noise\"][0]\n",
    "        #likelihood.noise_covar.noise = torch.rand(1) + 0.001\n",
    "        log_loss = -loss * model.train_inputs[0].numel()\n",
    "        2*log_loss + 2*sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        for kernel in get_kernels_in_kernel_expression(model.covar_module):\n",
    "            hypers = limits[kernel._get_name()]\n",
    "            for hyperparameter in hypers:\n",
    "                new_value = torch.rand(1) * (hypers[hyperparameter][1] - hypers[hyperparameter][0]) + hypers[hyperparameter][0]\n",
    "                setattr(kernel, hyperparameter, new_value)\n",
    "    except:\n",
    "        print(j)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ab5992c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6389451622962952\n",
      "0.023219872266054153\n",
      "0.29236135746724906\n",
      "0.0254241432857154\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.max(noise_list))\n",
    "print(np.min(noise_list))\n",
    "print(np.mean(noise_list))\n",
    "print(np.std(noise_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
