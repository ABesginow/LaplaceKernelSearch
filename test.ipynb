{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import torch\n",
    "import numpy as np\n",
    "import metrics\n",
    "# To run STAN in a Jupyter notebook\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.Tensor([0, 0])\n",
    "train_y = torch.Tensor([0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ZeroMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = torch.optim.Adam(model.parameters(), 0.1)\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "for i in range(50):\n",
    "    output = model(train_x)\n",
    "    loss = -mll(output, train_x)\n",
    "    loss.backward() \n",
    "    adam.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-1.2098, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " {'neg MLL': tensor(-1.7903, grad_fn=<NegBackward0>),\n",
       "  'punish term': tensor(-3.0001, dtype=torch.float64),\n",
       "  'punish without replacement': tensor(inf, dtype=torch.float64),\n",
       "  'laplace without replacement': tensor(inf, dtype=torch.float64, grad_fn=<SubBackward0>),\n",
       "  'num_replaced': tensor(3),\n",
       "  'parameter list': ['likelihood.noise_covar.raw_noise',\n",
       "   'covar_module.raw_outputscale',\n",
       "   'covar_module.base_kernel.raw_lengthscale'],\n",
       "  'parameter values': tensor([[-5.9927],\n",
       "          [-5.9931],\n",
       "          [ 0.0000]]),\n",
       "  'corrected Hessian': tensor([[ 4.6427e+01, -6.5769e-16,  0.0000e+00],\n",
       "          [ 1.1284e-15,  4.6427e+01,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  4.6427e+01]], dtype=torch.float64),\n",
       "  'diag(constructed eigvals)': tensor([46.4268, 46.4268, 46.4268], dtype=torch.float64),\n",
       "  'original symmetrized Hessian': tensor([[ 0.0639, -0.0540,  0.0000],\n",
       "          [-0.0540,  0.0559,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64),\n",
       "  'prior mean': tensor([[-3.5164],\n",
       "          [-1.6253],\n",
       "          [-0.2122]], dtype=torch.float64),\n",
       "  'diag(prior var)': tensor([12.8388,  5.0941,  3.5704], dtype=torch.float64),\n",
       "  'likelihood approximation': tensor(-1.2098, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       "  'Derivative time': 0.0017390251159667969,\n",
       "  'Approximation time': 0.00031757354736328125,\n",
       "  'Correction time': 0.00013875961303710938,\n",
       "  'Prior generation time': 0.0001068115234375,\n",
       "  'Total time': 0.0022704601287841797})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(train_x)\n",
    "loss = -mll(output, train_x)\n",
    "metrics.calculate_laplace(model, -loss, with_prior=True, param_punish_term=-1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/besginow/anaconda3/envs/sage/lib/python3.10/site-packages/gpytorch/models/exact_gp.py:274: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    output = model(train_x)\n",
    "    observed_pred = likelihood(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0034, 0.0009],\n",
       "        [0.0009, 0.0034]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_pred.covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0658, 0.0658])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_pred.loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Messages from stanc:\n",
      "Warning in '/tmp/httpstan_njirf1m1/model_mo3nc6ll.stan', line 5, column 12: A\n",
      "    control flow statement inside function softplus depends on argument v. At\n",
      "    '/tmp/httpstan_njirf1m1/model_mo3nc6ll.stan', line 32, column 74 to\n",
      "    column 82, the value of v depends on parameter(s): theta.\n",
      "Warning in '/tmp/httpstan_njirf1m1/model_mo3nc6ll.stan', line 5, column 12: A\n",
      "    control flow statement inside function softplus depends on argument v. At\n",
      "    '/tmp/httpstan_njirf1m1/model_mo3nc6ll.stan', line 32, column 51 to\n",
      "    column 59, the value of v depends on parameter(s): theta.\n",
      "Warning in '/tmp/httpstan_njirf1m1/model_mo3nc6ll.stan', line 5, column 12: A\n",
      "    control flow statement inside function softplus depends on argument v. At\n",
      "    '/tmp/httpstan_njirf1m1/model_mo3nc6ll.stan', line 32, column 120 to\n",
      "    column 128, the value of v depends on parameter(s): theta.\n",
      "Warning: The parameter theta has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Sampling:   0%\n",
      "Sampling: 100% (2000/2000)\n",
      "Sampling: 100% (2000/2000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 2.3e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: multi_normal_lpdf: Covariance matrix is not symmetric. Covariance matrix[1,2] = -nan, but Covariance matrix[2,1] = -nan (in '/tmp/httpstan_nkkkdkya/model_mo3nc6ll.stan', line 34, column 8 to column 32)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: multi_normal_lpdf: Covariance matrix is not symmetric. Covariance matrix[1,2] = -nan, but Covariance matrix[2,1] = -nan (in '/tmp/httpstan_nkkkdkya/model_mo3nc6ll.stan', line 34, column 8 to column 32)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: multi_normal_lpdf: Covariance matrix is not symmetric. Covariance matrix[1,2] = -nan, but Covariance matrix[2,1] = -nan (in '/tmp/httpstan_nkkkdkya/model_mo3nc6ll.stan', line 34, column 8 to column 32)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: multi_normal_lpdf: Covariance matrix is not symmetric. Covariance matrix[1,2] = -nan, but Covariance matrix[2,1] = -nan (in '/tmp/httpstan_nkkkdkya/model_mo3nc6ll.stan', line 34, column 8 to column 32)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: multi_normal_lpdf: Covariance matrix is not symmetric. Covariance matrix[1,2] = -nan, but Covariance matrix[2,1] = -nan (in '/tmp/httpstan_nkkkdkya/model_mo3nc6ll.stan', line 34, column 8 to column 32)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "/home/besginow/anaconda3/envs/sage/lib/python3.10/site-packages/gpytorch/models/exact_gp.py:274: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1428.1642)\n",
      "{'Kernel code': '\\n    functions {\\n        array[] real softplus(array[] real v){\\n            array[num_elements(v)] real r;\\n            for (d in 1:num_elements(v)){\\n                r[d] = log(1.0 + exp(v[d]));\\n            }\\n            return r;\\n        }\\n        real softplus(real v){\\n            return log(1.0 + exp(v));\\n        }\\n    }\\n    \\n    data {\\n        int N;\\n        int D;\\n        array[N] real x;\\n        vector[N] y;\\n        vector[D] t_mu;\\n        matrix[D, D] t_sigma;\\n    }\\n    \\n    parameters {\\n        vector<lower=-3.0>[D] theta;\\n    }\\n    \\n    model {\\n        matrix[N, N] K;\\n        vector[N] mu;\\n        theta ~ multi_normal(t_mu, t_sigma);\\n        K = (identity_matrix(dims(x)[1]).*softplus(theta[1])) + (softplus(theta[2]) .* gp_exp_quad_cov(x, 1.0, softplus(theta[3])));\\n        mu = zeros_vector(N);\\n        y ~ multi_normal(mu, K);\\n    }\\n    ', 'seed': 359318, 'Likelihood time': 1.527285099029541, 'Model compile time': 0.009491205215454102, 'Sampling time': 0.22682571411132812, 'Total time': 1.9295308589935303, 'Bad entries': 0, 'Parameter statistics': {'theta.1': {'mu': -1.665101584201602, 'var': 1.4798187725856746}, 'theta.2': {'mu': -1.1850699390225565, 'var': 1.8123944981389606}, 'theta.3': {'mu': -0.05156273554606321, 'var': 2.790047788202036}}, 'Parameter prior': {'mu': tensor([[-3.5164],\n",
      "        [-1.6253],\n",
      "        [-0.2122]]), 'var': tensor([[12.8388,  0.0000,  0.0000],\n",
      "        [ 0.0000,  5.0941,  0.0000],\n",
      "        [ 0.0000,  0.0000,  3.5704]])}, 'likelihood approximation': tensor(-1428.1642)}\n"
     ]
    }
   ],
   "source": [
    "from metrics import calculate_mc_STAN\n",
    "# Perform MCMC\n",
    "MCMC_approx, MC_log = calculate_mc_STAN(\n",
    "    model, likelihood, 1000)\n",
    "MC_logs = dict()\n",
    "print(MCMC_approx)\n",
    "print(MC_log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
