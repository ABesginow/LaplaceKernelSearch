{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f06fc330370>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"..\")\n",
    "import pprint\n",
    "import gpytorch\n",
    "import torch\n",
    "import numpy as np\n",
    "import metrics\n",
    "import copy\n",
    "import configparser\n",
    "from experiment_functions import Experiment\n",
    "from GaussianProcess import ExactGPModel\n",
    "from globalParams import options, hyperparameter_limits\n",
    "import gpytorch\n",
    "from helpFunctions import get_string_representation_of_kernel as gsr\n",
    "from helpFunctions import clean_kernel_expression\n",
    "from helpFunctions import get_kernels_in_kernel_expression, get_full_kernels_in_kernel_expression\n",
    "from helpFunctions import amount_of_base_kernels\n",
    "from itertools import product\n",
    "import json\n",
    "from kernelSearch import *\n",
    "from matplotlib import pyplot as plt\n",
    "from metrics import *\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import os\n",
    "import pdb\n",
    "import pickle\n",
    "import random\n",
    "import tikzplotlib\n",
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib as mpl\n",
    "from pygranso.pygranso import pygranso\n",
    "from pygranso.pygransoStruct import pygransoStruct\n",
    "from pygranso.private.getNvar import getNvarTorch\n",
    "\n",
    "# To run STAN in a Jupyter notebook\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def log_prior(model, theta_mu=None, sigma=None):\n",
    "    # params -\n",
    "    # TODO de-spaghettize this once the priors are coded properly\n",
    "    prior_dict = {'SE': {'raw_lengthscale' : {\"mean\": -0.21221139138922668 , \"std\":1.8895426067756804}},\n",
    "                  'MAT52': {'raw_lengthscale' :{\"mean\": 0.7993038925994188, \"std\":2.145122566357853 } },\n",
    "                  'MAT32': {'raw_lengthscale' :{\"mean\": 1.5711054238673443, \"std\":2.4453761235991216 } },\n",
    "                  'RQ': {'raw_lengthscale' :{\"mean\": -0.049841950913676276, \"std\":1.9426354614713097 },\n",
    "                          'raw_alpha' :{\"mean\": 1.882148553921053, \"std\":3.096431944989054 } },\n",
    "                  'PER':{'raw_lengthscale':{\"mean\": 0.7778461197268618, \"std\":2.288946656544974 },\n",
    "                          'raw_period_length':{\"mean\": 0.6485334993738499, \"std\":0.9930632050553377 } },\n",
    "                  'LIN':{'raw_variance' :{\"mean\": -0.8017903983055685, \"std\":0.9966569921354465 } },\n",
    "                  'c':{'raw_outputscale':{\"mean\": -1.6253091096349706, \"std\":2.2570021716661923 } },\n",
    "                  'noise': {'raw_noise':{\"mean\": -3.51640656386717, \"std\":3.5831320474767407 }}}\n",
    "    #prior_dict = {\"SE\": {\"raw_lengthscale\": {\"mean\": 0.891, \"std\": 2.195}},\n",
    "    #              \"MAT\": {\"raw_lengthscale\": {\"mean\": 1.631, \"std\": 2.554}},\n",
    "    #              \"PER\": {\"raw_lengthscale\": {\"mean\": 0.338, \"std\": 2.636},\n",
    "    #                      \"raw_period_length\": {\"mean\": 0.284, \"std\": 0.902}},\n",
    "    #              \"LIN\": {\"raw_variance\": {\"mean\": -1.463, \"std\": 1.633}},\n",
    "    #              \"c\": {\"raw_outputscale\": {\"mean\": -2.163, \"std\": 2.448}},\n",
    "    #              \"noise\": {\"raw_noise\": {\"mean\": -1.792, \"std\": 3.266}}}\n",
    "\n",
    "    variances_list = list()\n",
    "    debug_param_name_list = list()\n",
    "    theta_mu = list()\n",
    "    params = list()\n",
    "    covar_string = gsr(model.covar_module)\n",
    "    covar_string = covar_string.replace(\"(\", \"\")\n",
    "    covar_string = covar_string.replace(\")\", \"\")\n",
    "    covar_string = covar_string.replace(\" \", \"\")\n",
    "    covar_string = covar_string.replace(\"PER\", \"PER+PER\")\n",
    "    covar_string_list = [s.split(\"*\") for s in covar_string.split(\"+\")]\n",
    "    covar_string_list.insert(0, [\"LIKELIHOOD\"])\n",
    "    covar_string_list = list(chain.from_iterable(covar_string_list))\n",
    "    both_PER_params = False\n",
    "    for (param_name, param), cov_str in zip(model.named_parameters(), covar_string_list):\n",
    "        params.append(param.item())\n",
    "        debug_param_name_list.append(param_name)\n",
    "        # First param is (always?) noise and is always with the likelihood\n",
    "        if \"likelihood\" in param_name:\n",
    "            theta_mu.append(prior_dict[\"noise\"][\"raw_noise\"][\"mean\"])\n",
    "            variances_list.append(prior_dict[\"noise\"][\"raw_noise\"][\"std\"])\n",
    "            continue\n",
    "        else:\n",
    "            if (cov_str == \"PER\" or cov_str == \"RQ\") and not both_PER_params:\n",
    "                theta_mu.append(prior_dict[cov_str][param_name.split(\".\")[-1]][\"mean\"])\n",
    "                variances_list.append(prior_dict[cov_str][param_name.split(\".\")[-1]][\"std\"])\n",
    "                both_PER_params = True\n",
    "            elif (cov_str == \"PER\" or cov_str == \"RQ\") and both_PER_params:\n",
    "                theta_mu.append(prior_dict[cov_str][param_name.split(\".\")[-1]][\"mean\"])\n",
    "                variances_list.append(prior_dict[cov_str][param_name.split(\".\")[-1]][\"std\"])\n",
    "                both_PER_params = False\n",
    "            else:\n",
    "                try:\n",
    "                    theta_mu.append(prior_dict[cov_str][param_name.split(\".\")[-1]][\"mean\"])\n",
    "                    variances_list.append(prior_dict[cov_str][param_name.split(\".\")[-1]][\"std\"])\n",
    "                except Exception as E:\n",
    "                    import pdb\n",
    "                    pdb.set_trace()\n",
    "                    prev_cov = cov_str\n",
    "    theta_mu = torch.tensor(theta_mu)\n",
    "    theta_mu = theta_mu.unsqueeze(0).t()\n",
    "    sigma = torch.diag(torch.Tensor(variances_list))\n",
    "    sigma = sigma@sigma\n",
    "    prior = torch.distributions.MultivariateNormal(theta_mu.t(), sigma)\n",
    "\n",
    "    # for convention reasons I'm diving by the number of datapoints\n",
    "    return prior.log_prob(torch.Tensor(params)).item() / len(*model.train_inputs)\n",
    "\n",
    "\n",
    "\n",
    "def random_reinit(model):\n",
    "    for i, (param, limit) in enumerate(zip(model.parameters(), [{\"Noise\": hyperparameter_limits[\"Noise\"]},*[hyperparameter_limits[kernel] for kernel in get_full_kernels_in_kernel_expression(model.covar_module)]])):\n",
    "        covar_text = gsr(model.covar_module)\n",
    "        param_name = list(limit.keys())[0]\n",
    "        new_param_value = torch.randn_like(param) * (limit[param_name][1] - limit[param_name][0]) + limit[param_name][0]\n",
    "        param.data = new_param_value\n",
    "\n",
    "\n",
    "\n",
    "def optimize_hyperparameters(model, likelihood, **kwargs):\n",
    "    \"\"\"\n",
    "    find optimal hyperparameters either by BO or by starting from random initial values multiple times, using an optimizer every time\n",
    "    and then returning the best result\n",
    "    \"\"\"\n",
    "    log_param_path = kwargs.get(\"log_param_path\", False)\n",
    "    log_likelihood = kwargs.get(\"log_likelihood\", False)\n",
    "    random_restarts = kwargs.get(\"random_restarts\", options[\"training\"][\"restarts\"]+1)\n",
    "    line_search = kwargs.get(\"line_search\", False)\n",
    "    BFGS_iter = kwargs.get(\"BFGS_iter\", 50)\n",
    "    train_iterations = kwargs.get(\"train_iterations\", 0)\n",
    "    X = kwargs.get(\"X\", model.train_inputs)\n",
    "    Y = kwargs.get(\"Y\", model.train_targets)\n",
    "    with_BFGS = kwargs.get(\"with_BFGS\", False)\n",
    "    history_size = kwargs.get(\"history_size\", 100)\n",
    "    MAP = kwargs.get(\"MAP\", True)\n",
    "    prior = kwargs.get(\"prior\", False)\n",
    "    granso = kwargs.get(\"granso\", True)\n",
    "\n",
    "    if log_likelihood:\n",
    "        likelihood_log = list()\n",
    "        best_likelihood_log = likelihood_log\n",
    "    if log_param_path:\n",
    "        param_log_dict = {param_name[0] : list() for param_name in model.named_parameters()}\n",
    "        for param_name in model.named_parameters():\n",
    "            param_log_dict[param_name[0]].append(param_name[1].item())\n",
    "        best_param_log_dict = param_log_dict\n",
    "\n",
    "\n",
    "    mll = gpt.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    best_loss = -mll(model(X), Y)\n",
    "    best_model_state_dict = model.state_dict()\n",
    "    best_likelihood_state_dict = likelihood.state_dict()\n",
    "    \n",
    "\n",
    "    for restart in range(random_restarts):\n",
    "        try:\n",
    "            #optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "            #mll = gpt.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "            ## Train the ADAM part\n",
    "            #for _ in range(train_iterations):\n",
    "            #    optimizer.zero_grad()\n",
    "            #    output = model(X)\n",
    "            #    loss = -mll(output, Y)\n",
    "            #    if MAP:\n",
    "            #        log_p = log_prior(model)\n",
    "            #        loss -= log_p\n",
    "            #    loss.backward()\n",
    "            #    optimizer.step()\n",
    "            #    if log_param_path:\n",
    "            #        for param_name in model.named_parameters():\n",
    "            #            param_log_dict[param_name[0]].append(param_name[1].item())\n",
    "            #    if log_likelihood:\n",
    "            #        likelihood_log.append(loss.item())\n",
    "            ## Train the L-BFGS part\n",
    "            #if with_BFGS:\n",
    "            #    optimizer = torch.optim.LBFGS(model.parameters(), history_size=history_size, max_iter=BFGS_iter, line_search_fn=None if not line_search else \"strong_wolfe\")\n",
    "            #    def closure():\n",
    "            #        optimizer.zero_grad()\n",
    "            #        output = model(X)\n",
    "            #        loss = -mll(output, Y)\n",
    "            #        if MAP:\n",
    "            #            log_p = log_prior(model)\n",
    "            #            loss -= log_p\n",
    "            #        loss.backward()\n",
    "            #        return loss\n",
    "            #    loss = optimizer.step(closure)\n",
    "            if granso:\n",
    "                print(\"I USE GRANSO\")\n",
    "                # Set up the PyGRANSO optimizer\n",
    "                opts = pygransoStruct()\n",
    "                opts.torch_device = torch.device('cpu')\n",
    "                nvar = getNvarTorch(model.parameters())\n",
    "                opts.x0 = torch.nn.utils.parameters_to_vector(model.parameters()).detach().reshape(nvar,1)\n",
    "                opts.opt_tol = 1e-10\n",
    "                opts.limited_mem_size = 100\n",
    "                opts.globalAD = True\n",
    "                opts.quadprog_info_msg = False\n",
    "                opts.print_level = 0\n",
    "                opts.halt_on_linesearch_bracket = False\n",
    "\n",
    "                # Define the objective function\n",
    "                def objective_function(model):\n",
    "                    output = model(X)\n",
    "                    loss = -mll(output, Y)\n",
    "                    if MAP:\n",
    "                        log_p = log_prior(model)\n",
    "                        loss -= log_p\n",
    "                    print(loss)\n",
    "                    return [loss, None, None]\n",
    "\n",
    "                print(f\"pre training: {list(model.named_parameters())} w. loss: {objective_function(model)[0]}\")\n",
    "                # Train the model using PyGRANSO\n",
    "                soln = pygranso(var_spec=model, combined_fn=objective_function, user_opts=opts)\n",
    "                print(f\"post training: {list(model.named_parameters())} w. loss: {soln.final.f}\")\n",
    "                print(f\"post training: {list(model.named_parameters())} w. loss: {soln.best.f}\")\n",
    "\n",
    "            # I can't log using the closure since it's called too often when using line search\n",
    "            if log_param_path:\n",
    "                if with_BFGS:\n",
    "                    for param_num, param_name in enumerate(model.named_parameters()):\n",
    "                        if len(optimizer.state_dict()[\"state\"]) > 1:\n",
    "                            pdb.set_trace()\n",
    "                        for step in optimizer.state_dict()[\"state\"][0][\"old_stps\"]:\n",
    "                            param_log_dict[param_name[0]].append(param_log_dict[param_name[0]][-1] + step[param_num])\n",
    "            if log_likelihood:\n",
    "                likelihood_log.append(loss.item())\n",
    "            #if loss < best_loss:\n",
    "            #    best_loss = loss\n",
    "            #    best_model_state_dict = model.state_dict()\n",
    "            #    best_likelihood_state_dict = likelihood.state_dict()\n",
    "            #    if any([log_likelihood, log_param_path]):\n",
    "            #        if log_likelihood:\n",
    "            #            best_likelihood_log = likelihood_log \n",
    "            #            likelihood_log = list()\n",
    "            #        if log_param_path:\n",
    "            #            best_param_log_dict = param_log_dict\n",
    "            #            param_log_dict = {param_name[0] : list() for param_name in model.named_parameters()}\n",
    "        # Training blew up\n",
    "        except Exception as E:\n",
    "            random_reinit(model)\n",
    "            pass \n",
    "        # print output if enabled\n",
    "        if options[\"training\"][\"print_optimizing_output\"]:\n",
    "            print(f\"HYPERPARAMETER OPTIMIZATION: Random Restart {restart}: loss: {loss}, optimal loss: {best_loss}\")\n",
    "        random_reinit(model)\n",
    "    #model.load_state_dict(best_model_state_dict)\n",
    "    #likelihood.load_state_dict(best_likelihood_state_dict)\n",
    "\n",
    "    # Zero gradients from previous iteration\n",
    "    #optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(X)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, Y)\n",
    "    if MAP:\n",
    "        log_p = log_prior(model)\n",
    "        loss -= log_p\n",
    "    if any([log_likelihood, log_param_path]):\n",
    "        logables = dict()\n",
    "        if log_likelihood:\n",
    "            logables[\"log_likelihood\"] = best_likelihood_log\n",
    "        if log_param_path:\n",
    "            logables[\"log_param_path\"] = best_param_log_dict\n",
    "        return loss, logables, model, likelihood\n",
    "    else:\n",
    "        return loss, model, likelihood\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the training loop\n",
    "def optimize_hyperparameters2(model, likelihood, train_x, train_y):\n",
    "    # Set up the likelihood and model\n",
    "    #likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    #model = GPModel(train_x, train_y, likelihood)\n",
    "\n",
    "    # Define the negative log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    # Set up the PyGRANSO optimizer\n",
    "    opts = pygransoStruct()\n",
    "    opts.torch_device = torch.device('cpu')\n",
    "    nvar = getNvarTorch(model.parameters())\n",
    "    opts.x0 = torch.nn.utils.parameters_to_vector(model.parameters()).detach().reshape(nvar,1)\n",
    "    opts.opt_tol = 1e-10\n",
    "    opts.limited_mem_size = 100\n",
    "    opts.globalAD = True\n",
    "    opts.quadprog_info_msg = False\n",
    "    opts.print_level = 0\n",
    "    opts.halt_on_linesearch_bracket = False\n",
    "\n",
    "    # Define the objective function\n",
    "    def objective_function(model):\n",
    "        output = model(train_x)\n",
    "        loss = -mll(output, train_y)\n",
    "        log_p = log_prior(model)\n",
    "        loss -= log_p\n",
    "        return [loss, None, None]\n",
    "\n",
    "    best_model_state_dict = model.state_dict()\n",
    "    best_likelihood_state_dict = likelihood.state_dict()\n",
    "\n",
    "    random_restarts = 5\n",
    "    best_f = np.inf\n",
    "    for restart in range(random_restarts):\n",
    "        # Train the model using PyGRANSO\n",
    "        soln = pygranso(var_spec=model, combined_fn=objective_function, user_opts=opts)\n",
    "        if soln.final.f < best_f:\n",
    "            best_f = soln.final.f\n",
    "            best_model_state_dict = model.state_dict()\n",
    "            best_likelihood_state_dict = likelihood.state_dict()\n",
    "        print(f\"post training (final): {list(model.named_parameters())} w. loss: {soln.final.f}\")\n",
    "        random_reinit(model)\n",
    "\n",
    "    model.load_state_dict(best_model_state_dict)\n",
    "    likelihood.load_state_dict(best_likelihood_state_dict)\n",
    "\n",
    "    loss = -mll(model(train_x), train_y)\n",
    "    log_p = log_prior(model)\n",
    "    loss -= log_p\n",
    "\n",
    "    print(f\"post training (best): {list(model.named_parameters())} w. loss: {soln.best.f}\")\n",
    "    print(f\"post training (final): {list(model.named_parameters())} w. loss: {soln.final.f}\")\n",
    "    #torch.autograd.grad(mll, params_list, retain_graph=True, create_graph=True, allow_unused=True)\n",
    "    # Return the trained model\n",
    "    return loss, model, likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_std_points(mu, K):\n",
    "    x, y = np.mgrid[-3:3:.1, -3:3:.1]\n",
    "    rv = multivariate_normal(mu, K)\n",
    "    L = np.linalg.cholesky(K)\n",
    "\n",
    "    data = np.dstack((x, y))\n",
    "    z = rv.pdf(data)\n",
    "\n",
    "    # Drawing the unit circle\n",
    "    # x^2 + y^2 = 1\n",
    "    precision = 50\n",
    "    unit_x = torch.cat([torch.linspace(-1, 1, precision), torch.linspace(-1, 1, precision)])\n",
    "    unit_y = torch.cat([torch.sqrt(1 - torch.linspace(-1, 1, precision)**2), -torch.sqrt(1 - torch.linspace(-1, 1, precision)**2)])\n",
    "\n",
    "    new_unit_x = list()\n",
    "    new_unit_y = list()\n",
    "\n",
    "    for tx, ty in zip(unit_x, unit_y):\n",
    "        res = np.array([tx, ty]) @ L\n",
    "        new_unit_x.append(mu[0] + 2*res[0])\n",
    "        new_unit_y.append(mu[1] + 2*res[1])\n",
    "    return new_unit_x, new_unit_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-diddling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "figure_path = \"linear_figures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f061a374b50>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "END = 1\n",
    "COUNT = 10\n",
    "train_x = torch.linspace(0, END, COUNT)\n",
    "train_y = torch.linspace(0, END, COUNT)\n",
    "train_y += torch.randn(train_x.size()) * torch.sqrt(torch.tensor(0.1))\n",
    "plt.plot(train_x, train_y, \"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplest GP possible. SE with constant sigma_f \n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ZeroMean()\n",
    "        self.covar_module = gpytorch.kernels.RBFKernel()\n",
    "        #self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel())\n",
    "        #self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.PeriodicKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "#likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_constraint=gpytorch.constraints.GreaterThan(1e-30))\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8.3621e+00,  1.5041e+00,  1.2708e-01,  6.5276e-03,  2.2986e-04,\n",
      "         5.6375e-06,  2.2122e-07,  3.9967e-08, -2.4226e-08, -8.4223e-08],\n",
      "       grad_fn=<FlipBackward0>)\n",
      "tensor([[1.0000, 0.9872, 0.9499, 0.8908, 0.8142, 0.7253, 0.6297, 0.5328, 0.4394,\n",
      "         0.3532],\n",
      "        [0.9872, 1.0000, 0.9872, 0.9499, 0.8908, 0.8142, 0.7253, 0.6297, 0.5328,\n",
      "         0.4394],\n",
      "        [0.9499, 0.9872, 1.0000, 0.9872, 0.9499, 0.8908, 0.8142, 0.7253, 0.6297,\n",
      "         0.5328],\n",
      "        [0.8908, 0.9499, 0.9872, 1.0000, 0.9872, 0.9499, 0.8908, 0.8142, 0.7253,\n",
      "         0.6297],\n",
      "        [0.8142, 0.8908, 0.9499, 0.9872, 1.0000, 0.9872, 0.9499, 0.8908, 0.8142,\n",
      "         0.7253],\n",
      "        [0.7253, 0.8142, 0.8908, 0.9499, 0.9872, 1.0000, 0.9872, 0.9499, 0.8908,\n",
      "         0.8142],\n",
      "        [0.6297, 0.7253, 0.8142, 0.8908, 0.9499, 0.9872, 1.0000, 0.9872, 0.9499,\n",
      "         0.8908],\n",
      "        [0.5328, 0.6297, 0.7253, 0.8142, 0.8908, 0.9499, 0.9872, 1.0000, 0.9872,\n",
      "         0.9499],\n",
      "        [0.4394, 0.5328, 0.6297, 0.7253, 0.8142, 0.8908, 0.9499, 0.9872, 1.0000,\n",
      "         0.9872],\n",
      "        [0.3532, 0.4394, 0.5328, 0.6297, 0.7253, 0.8142, 0.8908, 0.9499, 0.9872,\n",
      "         1.0000]], grad_fn=<RBFCovarianceBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.linalg.eigh(model(train_x).covariance_matrix)[0].flip(0))\n",
    "print(model(train_x).covariance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/besginow/anaconda3/envs/sage/lib/python3.10/site-packages/pygranso/private/bfgsHessianInverseLimitedMem.py:237: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /home/conda/feedstock_root/build_artifacts/pytorch-recipe_1675740247391/work/aten/src/ATen/native/TensorShape.cpp:3277.)\n",
      "  alpha[j,:]  = self.rho[0,j] * (self.S[:,j].T  @ q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post training (final): [('likelihood.noise_covar.raw_noise', Parameter containing:\n",
      "tensor([-2.4198], dtype=torch.float64, requires_grad=True)), ('covar_module.raw_lengthscale', Parameter containing:\n",
      "tensor([[0.5204]], dtype=torch.float64, requires_grad=True))] w. loss: 0.9174853492359207\n",
      "post training (final): [('likelihood.noise_covar.raw_noise', Parameter containing:\n",
      "tensor([-2.4198], dtype=torch.float64, requires_grad=True)), ('covar_module.raw_lengthscale', Parameter containing:\n",
      "tensor([[0.5204]], dtype=torch.float64, requires_grad=True))] w. loss: 0.9174853492359207\n",
      "post training (final): [('likelihood.noise_covar.raw_noise', Parameter containing:\n",
      "tensor([-2.4198], dtype=torch.float64, requires_grad=True)), ('covar_module.raw_lengthscale', Parameter containing:\n",
      "tensor([[0.5204]], dtype=torch.float64, requires_grad=True))] w. loss: 0.9174853492359207\n",
      "post training (final): [('likelihood.noise_covar.raw_noise', Parameter containing:\n",
      "tensor([-2.4198], dtype=torch.float64, requires_grad=True)), ('covar_module.raw_lengthscale', Parameter containing:\n",
      "tensor([[0.5204]], dtype=torch.float64, requires_grad=True))] w. loss: 0.9174853492359207\n",
      "post training (final): [('likelihood.noise_covar.raw_noise', Parameter containing:\n",
      "tensor([-2.4198], dtype=torch.float64, requires_grad=True)), ('covar_module.raw_lengthscale', Parameter containing:\n",
      "tensor([[0.5204]], dtype=torch.float64, requires_grad=True))] w. loss: 0.9174853492359207\n",
      "post training (best): [('likelihood.noise_covar.raw_noise', Parameter containing:\n",
      "tensor([-2.4198], dtype=torch.float64, requires_grad=True)), ('covar_module.raw_lengthscale', Parameter containing:\n",
      "tensor([[0.5204]], dtype=torch.float64, requires_grad=True))] w. loss: 0.9174280287755487\n",
      "post training (final): [('likelihood.noise_covar.raw_noise', Parameter containing:\n",
      "tensor([-2.4198], dtype=torch.float64, requires_grad=True)), ('covar_module.raw_lengthscale', Parameter containing:\n",
      "tensor([[0.5204]], dtype=torch.float64, requires_grad=True))] w. loss: 0.9174853492359207\n"
     ]
    }
   ],
   "source": [
    "num_train_iter = 0\n",
    "use_MAP = True \n",
    "use_LBFGS = False\n",
    "LBFGS_iter = 50\n",
    "# Train the MAP for 100 Iterations of ADAM and then 50 more of L-BFGS\n",
    "loss, model, likelihood = optimize_hyperparameters2(model, likelihood, train_x, train_y)\n",
    "#loss,  model, likelihood = optimize_hyperparameters(model, likelihood, \n",
    "#                                                                 line_search=False, \n",
    "#                                                                 X=train_x, \n",
    "#                                                                 Y=train_y, \n",
    "#                                                                 train_iterations=0, \n",
    "#                                                                 #BFGS_iter=LBFGS_iter, \n",
    "#                                                                 #history_size=2*LBFGS_iter, \n",
    "#                                                                 #with_BFGS=use_LBFGS, \n",
    "#                                                                 #MAP=use_MAP, \n",
    "#                                                                 log_param_path=False, \n",
    "#                                                                 random_restarts=1, \n",
    "#                                                                 log_likelihood=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9175, dtype=torch.float64, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('likelihood.noise_covar.raw_noise',\n",
       "  Parameter containing:\n",
       "  tensor([-2.4198], dtype=torch.float64, requires_grad=True)),\n",
       " ('covar_module.raw_lengthscale',\n",
       "  Parameter containing:\n",
       "  tensor([[0.5204]], dtype=torch.float64, requires_grad=True))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_396172/1726920860.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'training_log' is not defined"
     ]
    }
   ],
   "source": [
    "training_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.linalg.eigh(model(train_x).covariance_matrix)[0].flip(0))\n",
    "print(model(train_x).covariance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'MAP' if use_MAP else 'likelihood'}:{loss}\")\n",
    "print(list(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.likelihood.noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(0, 1, 51)\n",
    "    a = model(test_x)\n",
    "    observed_pred = likelihood(a)\n",
    "    \n",
    "with torch.no_grad():\n",
    "    # Initialize plot\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = observed_pred.confidence_region()\n",
    "    # Plot training data as black stars\n",
    "    ax.plot(train_x.numpy(), train_y.numpy(), 'k*')\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x.numpy(), observed_pred.mean.numpy(), 'b')\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_pred.confidence_region()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(training_log[\"log_param_path\"]['likelihood.noise_covar.raw_noise'])\n",
    "#plt.plot(training_log[\"log_likelihood\"])\n",
    "param_keys = list(training_log[\"log_param_path\"].keys())\n",
    "filtered = False \n",
    "filtered_noise = list()\n",
    "filtered_length = list()\n",
    "filtered_loglike = list()\n",
    "\n",
    "# loop to filter draws below X \n",
    "for n, l, llik in zip(training_log[\"log_param_path\"][param_keys[0]], training_log[\"log_param_path\"][param_keys[1]], training_log[\"log_likelihood\"]):\n",
    "    if llik > -5000:\n",
    "        filtered_noise.append(n)\n",
    "        filtered_length.append(l)\n",
    "        filtered_loglike.append(llik)\n",
    "\n",
    "if filtered:\n",
    "    for i in range(len(filtered_noise)-1):\n",
    "        n, l = filtered_noise[i], filtered_length[i]\n",
    "        n2, l2 = filtered_noise[i+1], filtered_length[i+1]\n",
    "        plt.arrow(n, l, n2-n, l2-l, color=mpl.colormaps[\"Greens\"](i/len(filtered_noise)), head_length = 0.07, head_width = 0.025, length_includes_head = True)\n",
    "    plt.scatter(filtered_noise, filtered_length, c=filtered_loglike, s=3)\n",
    "else:\n",
    "    for i in range(len(training_log[\"log_param_path\"][param_keys[0]])-1):\n",
    "        n, l = training_log[\"log_param_path\"][param_keys[0]][i], training_log[\"log_param_path\"][param_keys[1]][i]\n",
    "        n2, l2 = training_log[\"log_param_path\"][param_keys[0]][i+1], training_log[\"log_param_path\"][param_keys[1]][i+1]\n",
    "        plt.arrow(n, l, n2-n, l2-l, color=mpl.colormaps[\"Greens\"](i/len(training_log[\"log_param_path\"][param_keys[0]])), head_length = 0.47, head_width = 0.55, length_includes_head = True)\n",
    "    plt.scatter(training_log[\"log_param_path\"][param_keys[0]], training_log[\"log_param_path\"][param_keys[1]], c=-torch.Tensor(training_log[\"log_likelihood\"]), s=3)\n",
    "plt.title(\"Log MAP (larger = better)\" if use_MAP else \"Log Likelihood (larger = better)\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.plot(training_log[\"log_param_path\"][param_keys[0]][-1], training_log[\"log_param_path\"][param_keys[1]][-1], \"ro\") \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\" Write me a loop that iterates over several raw noise values from -30 to 1 and plot the corresponding likelihood values, i.e. the MAP values\n",
    "\"\"\"\n",
    "def myMLL(model):\n",
    "    with torch.no_grad():\n",
    "        observed_pred_prior = likelihood(model(model.train_inputs[0]))\n",
    "\n",
    "    like_cov_chol = torch.linalg.cholesky(observed_pred_prior.covariance_matrix)\n",
    "    like_dist = torch.distributions.multivariate_normal.MultivariateNormal(observed_pred_prior.mean, scale_tril=like_cov_chol)\n",
    "    return like_dist.log_prob(model.train_targets)\n",
    "\n",
    "# noise and lengthscale ranges\n",
    "noise_range = torch.linspace(-25, -9, 10)\n",
    "length_range = torch.linspace(2, 2, 1)\n",
    "\n",
    "# make meshgrid\n",
    "noise_grid, length_grid = torch.meshgrid(noise_range, length_range)\n",
    "loss_list = list()\n",
    "\n",
    "for n_val, l_val in product(noise_range, length_range):\n",
    "    model.likelihood.raw_noise.data = torch.full_like(model.likelihood.raw_noise.data, n_val)\n",
    "    model.covar_module.raw_lengthscale.data = torch.full_like(model.covar_module.raw_lengthscale.data, l_val)\n",
    "    #model.likelihood.noise_covar.noise = n_val\n",
    "    #model.covar_module.raw_lengthscale = l_val\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "    loss = mll(model(train_x), train_y)\n",
    "    myloss = myMLL(model)\n",
    "    print(f\"noise: {n_val}, loss:{loss}, myloss:{myloss/len(train_x)}\")\n",
    "    loss_list.append(loss)\n",
    "\n",
    "\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "model.covar_module.raw_lengthscale.data = torch.full_like(model.covar_module.raw_lengthscale.data, torch.tensor(2))\n",
    "# Running model with a noise of -25 and a lengthscale of 2\n",
    "model.likelihood.raw_noise.data = torch.full_like(model.likelihood.raw_noise.data, torch.tensor(-25))\n",
    "loss = mll(model(train_x), train_y)\n",
    "myloss = myMLL(model)\n",
    "print(likelihood(model(train_x)).covariance_matrix)\n",
    "print(f\"-25 ({torch.nn.functional.softplus(torch.tensor(-25.))}) loss:{loss}, myloss:{myloss/len(train_x)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Running model with a noise of -9 and a lengthscale of 2\n",
    "model.likelihood.raw_noise.data = torch.full_like(model.likelihood.raw_noise.data, torch.tensor(-9))\n",
    "loss = mll(model(train_x), train_y)\n",
    "myloss = myMLL(model)\n",
    "print(likelihood(model(train_x)).covariance_matrix)\n",
    "print(f\"-9 ({torch.nn.functional.softplus(torch.tensor(-9.))}) loss:{loss}, myloss:{myloss/len(train_x)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "loss_max = max(loss_list)\n",
    "loss_min = min(loss_list)\n",
    "for (n_val, l_val), loss in zip(product(noise_range, length_range), loss_list):\n",
    "    plt.scatter(torch.nn.functional.softplus(n_val), torch.nn.functional.softplus(l_val), c=loss.detach().numpy(), vmin=loss_min, vmax=loss_max, s=3)\n",
    "plt.xlabel(\"raw noise\")\n",
    "plt.xscale(\"log\")\n",
    "plt.ylabel(\"raw lengthscale\")\n",
    "plt.yscale(\"log\")\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    observed_pred_prior = likelihood(model(model.train_inputs[0]))\n",
    "\n",
    "like_cov_chol = torch.linalg.cholesky(observed_pred_prior.covariance_matrix)\n",
    "like_dist = torch.distributions.multivariate_normal.MultivariateNormal(observed_pred_prior.mean, scale_tril=like_cov_chol)\n",
    "print(like_dist.log_prob(model.train_targets))\n",
    "print(-training_log[\"log_likelihood\"][-1]*COUNT)\n",
    "print(-loss*COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.linalg.eigh(observed_pred_prior.covariance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_log[\"training_log\"][:-50]\n",
    "len(training_log[\"log_likelihood\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"L-BFGS iterations: {len(training_log['log_likelihood']) - num_train_iter}\")\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "lap, lap_log = metrics.calculate_laplace(model, -loss, with_prior=True, param_punish_term=-1.0)\n",
    "print(lap)\n",
    "print(lap_log)\n",
    "\n",
    "# Draw the distribution defined by the mean (found parametrization) and covariance matrix (Hessian)\n",
    "# (4.133) in Bishop, 2006: f(z) ~ f(z_0)exp(-0.5 (z-z_0)^T H (z-z_0)) with z the parameters, and H the Hessian\n",
    "# We just leave out the f(z_0)\n",
    "\n",
    "scaling_factor = lap_log[\"neg MLL\"]\n",
    "mu = [training_log[\"log_param_path\"][param_keys[0]][-1], training_log[\"log_param_path\"][param_keys[1]][-1]]\n",
    "K = lap_log[\"corrected Hessian\"]\n",
    "new_unit_x, new_unit_y = get_std_points(mu, K.inverse()[:2, :2])\n",
    "plt.scatter(new_unit_x, new_unit_y, color=\"grey\", s=3)\n",
    "K = lap_log[\"original symmetrized Hessian\"]\n",
    "new_unit_x, new_unit_y = get_std_points(mu, K.inverse()[:2, :2])\n",
    "plt.scatter(new_unit_x, new_unit_y, color=\"black\", s=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.linalg.eigh(torch.tensor([[0.0453, 0.0083],\n",
    "        [0.0083, 0.0205]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import calculate_mc_STAN\n",
    "# Perform MCMC\n",
    "MCMC_approx, MC_log = calculate_mc_STAN(\n",
    "    model, likelihood, 1000, log_param_path=True, log_full_likelihood=True)\n",
    "print(MCMC_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w. 0 ADAM (MAP)\n",
    "#[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
    "#tensor([-11.8925], requires_grad=True)), ('covar_module.raw_lengthscale', Parameter containing:\n",
    "#tensor([[1.7432]], requires_grad=True))]\n",
    "# w. 50 ADAM\n",
    "# [('likelihood.noise_covar.raw_noise', Parameter containing:\n",
    "# tensor([-11.6812], requires_grad=True)), ('covar_module.raw_lengthscale', Parameter containing:\n",
    "# tensor([[1.5973]], requires_grad=True))]\n",
    "# w. 100 ADAM\n",
    "# [('likelihood.noise_covar.raw_noise', Parameter containing:\n",
    "# tensor([-10.8088], requires_grad=True)), ('covar_module.raw_lengthscale', Parameter containing:\n",
    "# tensor([[1.8571]], requires_grad=True))]\n",
    "\n",
    "#max_index = MC_log['manual lp list'].index(max(MC_log['manual lp list']))\n",
    "#for i, param in enumerate(MC_log['param draws dict']):\n",
    "#    print(f\"{lap_log['parameter list'][i]}:{MC_log['param draws dict'][param][max_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for param_name in MC_log['param draws dict']:\n",
    "    plt.hist(MC_log['param draws dict'][param_name])\n",
    "print(MC_log[\"Parameter prior\"])\n",
    "plt.savefig(f\"{figure_path}/MCMC_param_distribution_{COUNT}_datapoints.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(MC_log['manual lp list'])\n",
    "plt.title(\"Log Likelihood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MC_log[\"Parameter statistics\"])\n",
    "\n",
    "mu = [training_log[\"training_log\"][param_keys[0]][-1], training_log[\"training_log\"][param_keys[1]][-1]]\n",
    "K = lap_log[\"corrected Hessian\"]\n",
    "print(f\"{[training_log['training_log'][param_key][-1] for param_key in param_keys]}\")\n",
    "print(f\"{K.inverse().diag()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    max_index = MC_log['manual lp list'].index(max(MC_log['manual lp list']))\n",
    "    print(f\"{max(MC_log['manual lp list'])} : {MC_log['param draws dict']['theta.1'][max_index]} {MC_log['param draws dict']['theta.2'][max_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#scaling_factor = lap_log[\"neg MLL\"]\n",
    "#mu = [training_log[\"training_log\"][param_keys[0]][-1], training_log[\"training_log\"][param_keys[1]][-1]]\n",
    "#K = lap_log[\"corrected Hessian\"]\n",
    "#new_unit_x, new_unit_y = get_std_points(mu, K)\n",
    "##plt.scatter(new_unit_x, new_unit_y, color=\"grey\", s=3)\n",
    "#K = lap_log[\"original symmetrized Hessian\"]\n",
    "#new_unit_x, new_unit_y = get_std_points(mu, K)\n",
    "#plt.scatter(new_unit_x, new_unit_y, color=\"black\", s=3)\n",
    "#\n",
    "\n",
    "filtered = False \n",
    "filtered_noise = list()\n",
    "filtered_length = list()\n",
    "filtered_loglike = list()\n",
    "\n",
    "# loop to filter draws below X \n",
    "for n, l, llik in zip(MC_log['param draws dict'][\"theta.1\"], MC_log['param draws dict'][\"theta.2\"], MC_log['manual lp list']):\n",
    "    if llik > -100:\n",
    "        filtered_noise.append(n)\n",
    "        filtered_length.append(l)\n",
    "        filtered_loglike.append(llik)\n",
    "\n",
    "if filtered:\n",
    "    for i in range(len(filtered_noise)-1):\n",
    "        n, l = filtered_noise[i], filtered_length[i]\n",
    "        n2, l2 = filtered_noise[i+1], filtered_length[i+1]\n",
    "        #plt.arrow(n, l, n2-n, l2-l, color=mpl.colormaps[\"Greens\"](i/len(filtered_noise)), head_length = 0.07, head_width = 0.025, length_includes_head = True)\n",
    "    plt.scatter(filtered_noise, filtered_length, c=filtered_loglike, s=3)\n",
    "    max_index = MC_log['manual lp list'].index(max(MC_log['manual lp list']))\n",
    "    print(f\"{max(MC_log['manual lp list'])} : {MC_log['param draws dict']['theta.1'][max_index]} {MC_log['param draws dict']['theta.2'][max_index]}\")\n",
    "    plt.plot(MC_log['param draws dict'][\"theta.1\"][max_index], MC_log['param draws dict'][\"theta.2\"][max_index], \"ro\")\n",
    "else:\n",
    "    for i in range(len(MC_log['param draws dict'][\"theta.1\"])-1):\n",
    "        n, l = MC_log['param draws dict'][\"theta.1\"][i], MC_log['param draws dict'][\"theta.2\"][i]\n",
    "        n2, l2 = MC_log['param draws dict'][\"theta.1\"][i+1], MC_log['param draws dict'][\"theta.2\"][i+1]\n",
    "        #plt.arrow(n, l, n2-n, l2-l, color=mpl.colormaps[\"Greens\"](i/len(MC_log['param draws dict'][\"theta.1\"])), head_length = 0.07, head_width = 0.025, length_includes_head = True)\n",
    "    plt.scatter(MC_log['param draws dict'][\"theta.1\"], MC_log['param draws dict'][\"theta.2\"], c=torch.Tensor(MC_log['manual lp list']), s=3)\n",
    "    max_index = MC_log['manual lp list'].index(max(MC_log['manual lp list']))\n",
    "    plt.plot(MC_log['param draws dict'][\"theta.1\"][max_index], MC_log['param draws dict'][\"theta.2\"][max_index], \"ro\")\n",
    "\n",
    "plt.colorbar() \n",
    "\n",
    "mu = [training_log[\"training_log\"][param_keys[0]][-1], training_log[\"training_log\"][param_keys[1]][-1]]\n",
    "K = lap_log[\"corrected Hessian\"]\n",
    "new_unit_x, new_unit_y = get_std_points(mu, K.inverse()[:2, :2])\n",
    "#plt.scatter(new_unit_x, new_unit_y, color=\"black\", s=3)\n",
    "\n",
    "K = lap_log[\"original symmetrized Hessian\"]\n",
    "new_unit_x, new_unit_y = get_std_points(mu, K.inverse()[:2, :2])\n",
    "#plt.scatter(new_unit_x, new_unit_y, color=\"turquoise\", s=3)\n",
    "plt.title(\"Log Likelihood\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contour plot of the likelihood surface according to the explored samples\n",
    "# loop to filter draws below -5000\n",
    "filtered_noise = list()\n",
    "filtered_length = list()\n",
    "filtered_loglike = list()\n",
    "for n, l, llik in zip(MC_log['param draws dict'][\"theta.1\"], MC_log['param draws dict'][\"theta.2\"], MC_log['manual lp list']):\n",
    "    if llik > -5000:\n",
    "        filtered_noise.append(n)\n",
    "        filtered_length.append(l)\n",
    "        filtered_loglike.append(llik)\n",
    "plt.scatter(MC_log['param draws dict'][\"theta.1\"], MC_log['param draws dict'][\"theta.2\"], c=range(len(MC_log['param draws dict'][\"theta.2\"])), cmap=\"Greens\", s=2)\n",
    "plt.colorbar() \n",
    "## Drawing the parameter Prior\n",
    "new_unit_x, new_unit_y = get_std_points(MC_log[\"Parameter prior\"][\"mu\"].numpy().T[0][:2], MC_log[\"Parameter prior\"][\"var\"].inverse()[:2, :2])\n",
    "# Draw one standard deviation around the center of the distribution\n",
    "plt.scatter(new_unit_x, new_unit_y, color=\"pink\", s=3)\n",
    "#plt.scatter(filtered_noise, filtered_length, c=filtered_loglike)\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"Log Likelihood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f4(x):\n",
    "    return x + torch.log(-torch.expm1(-x))\n",
    "f4(torch.tensor(1e-4))\n",
    "torch.nn.functional.softplus(torch.tensor(-9.2102))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
