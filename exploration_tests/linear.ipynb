{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"..\")\n",
    "import pprint\n",
    "import gpytorch\n",
    "import torch\n",
    "import numpy as np\n",
    "import metrics\n",
    "import copy\n",
    "import configparser\n",
    "from experiment_functions import Experiment\n",
    "from GaussianProcess import ExactGPModel\n",
    "from globalParams import options, hyperparameter_limits\n",
    "import gpytorch\n",
    "from helpFunctions import get_string_representation_of_kernel as gsr\n",
    "from helpFunctions import clean_kernel_expression\n",
    "from helpFunctions import get_kernels_in_kernel_expression\n",
    "from helpFunctions import amount_of_base_kernels\n",
    "from itertools import product\n",
    "import json\n",
    "from kernelSearch import *\n",
    "from matplotlib import pyplot as plt\n",
    "from metrics import *\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import os\n",
    "import pdb\n",
    "import pickle\n",
    "import random\n",
    "import tikzplotlib\n",
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# To run STAN in a Jupyter notebook\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def log_prior(model, theta_mu=None, sigma=None):\n",
    "    # params -\n",
    "    # TODO de-spaghettize this once the priors are coded properly\n",
    "    prior_dict = {'SE': {'raw_lengthscale' : {\"mean\": -0.21221139138922668 , \"std\":1.8895426067756804}},\n",
    "                  'MAT52': {'raw_lengthscale' :{\"mean\": 0.7993038925994188, \"std\":2.145122566357853 } },\n",
    "                  'MAT32': {'raw_lengthscale' :{\"mean\": 1.5711054238673443, \"std\":2.4453761235991216 } },\n",
    "                  'RQ': {'raw_lengthscale' :{\"mean\": -0.049841950913676276, \"std\":1.9426354614713097 },\n",
    "                          'raw_alpha' :{\"mean\": 1.882148553921053, \"std\":3.096431944989054 } },\n",
    "                  'PER':{'raw_lengthscale':{\"mean\": 0.7778461197268618, \"std\":2.288946656544974 },\n",
    "                          'raw_period_length':{\"mean\": 0.6485334993738499, \"std\":0.9930632050553377 } },\n",
    "                  'LIN':{'raw_variance' :{\"mean\": -0.8017903983055685, \"std\":0.9966569921354465 } },\n",
    "                  'c':{'raw_outputscale':{\"mean\": -1.6253091096349706, \"std\":2.2570021716661923 } },\n",
    "                  'noise': {'raw_noise':{\"mean\": -3.51640656386717, \"std\":3.5831320474767407 }}}\n",
    "    #prior_dict = {\"SE\": {\"raw_lengthscale\": {\"mean\": 0.891, \"std\": 2.195}},\n",
    "    #              \"MAT\": {\"raw_lengthscale\": {\"mean\": 1.631, \"std\": 2.554}},\n",
    "    #              \"PER\": {\"raw_lengthscale\": {\"mean\": 0.338, \"std\": 2.636},\n",
    "    #                      \"raw_period_length\": {\"mean\": 0.284, \"std\": 0.902}},\n",
    "    #              \"LIN\": {\"raw_variance\": {\"mean\": -1.463, \"std\": 1.633}},\n",
    "    #              \"c\": {\"raw_outputscale\": {\"mean\": -2.163, \"std\": 2.448}},\n",
    "    #              \"noise\": {\"raw_noise\": {\"mean\": -1.792, \"std\": 3.266}}}\n",
    "\n",
    "    variances_list = list()\n",
    "    debug_param_name_list = list()\n",
    "    theta_mu = list()\n",
    "    params = list()\n",
    "    covar_string = gsr(model.covar_module)\n",
    "    covar_string = covar_string.replace(\"(\", \"\")\n",
    "    covar_string = covar_string.replace(\")\", \"\")\n",
    "    covar_string = covar_string.replace(\" \", \"\")\n",
    "    covar_string = covar_string.replace(\"PER\", \"PER+PER\")\n",
    "    covar_string_list = [s.split(\"*\") for s in covar_string.split(\"+\")]\n",
    "    covar_string_list.insert(0, [\"LIKELIHOOD\"])\n",
    "    covar_string_list = list(chain.from_iterable(covar_string_list))\n",
    "    both_PER_params = False\n",
    "    for (param_name, param), cov_str in zip(model.named_parameters(), covar_string_list):\n",
    "        params.append(param.item())\n",
    "        debug_param_name_list.append(param_name)\n",
    "        # First param is (always?) noise and is always with the likelihood\n",
    "        if \"likelihood\" in param_name:\n",
    "            theta_mu.append(prior_dict[\"noise\"][\"raw_noise\"][\"mean\"])\n",
    "            variances_list.append(prior_dict[\"noise\"][\"raw_noise\"][\"std\"])\n",
    "            continue\n",
    "        else:\n",
    "            if (cov_str == \"PER\" or cov_str == \"RQ\") and not both_PER_params:\n",
    "                theta_mu.append(prior_dict[cov_str][param_name.split(\".\")[-1]][\"mean\"])\n",
    "                variances_list.append(prior_dict[cov_str][param_name.split(\".\")[-1]][\"std\"])\n",
    "                both_PER_params = True\n",
    "            elif (cov_str == \"PER\" or cov_str == \"RQ\") and both_PER_params:\n",
    "                theta_mu.append(prior_dict[cov_str][param_name.split(\".\")[-1]][\"mean\"])\n",
    "                variances_list.append(prior_dict[cov_str][param_name.split(\".\")[-1]][\"std\"])\n",
    "                both_PER_params = False\n",
    "            else:\n",
    "                try:\n",
    "                    theta_mu.append(prior_dict[cov_str][param_name.split(\".\")[-1]][\"mean\"])\n",
    "                    variances_list.append(prior_dict[cov_str][param_name.split(\".\")[-1]][\"std\"])\n",
    "                except Exception as E:\n",
    "                    import pdb\n",
    "                    pdb.set_trace()\n",
    "                    prev_cov = cov_str\n",
    "    theta_mu = torch.tensor(theta_mu)\n",
    "    theta_mu = theta_mu.unsqueeze(0).t()\n",
    "    sigma = torch.diag(torch.Tensor(variances_list))\n",
    "    sigma = sigma@sigma\n",
    "    prior = torch.distributions.MultivariateNormal(theta_mu.t(), sigma)\n",
    "\n",
    "    # for convention reasons I'm diving by the number of datapoints\n",
    "    return prior.log_prob(torch.Tensor(params)).item() / len(*model.train_inputs)\n",
    "\n",
    "def optimize_hyperparameters(model, likelihood, train_iterations, X, Y, with_BFGS=False, MAP=False, prior=None, **kwargs):\n",
    "    \"\"\"\n",
    "    find optimal hyperparameters either by BO or by starting from random initial values multiple times, using an optimizer every time\n",
    "    and then returning the best result\n",
    "    \"\"\"\n",
    "    ## Setup\n",
    "    # Log the parameters found during training\n",
    "    log_param_path = kwargs.get(\"log_param_path\", False)\n",
    "    log_likelihood = kwargs.get(\"log_likelihood\", False)\n",
    "    random_restarts = kwargs.get(\"random_restarts\", options[\"training\"][\"restarts\"]+1)\n",
    "    best_loss = 1e400\n",
    "    optimal_parameters = dict()\n",
    "    limits = hyperparameter_limits\n",
    "    if log_param_path:\n",
    "        param_log_dict = {param_name[0] : list() for param_name in model.named_parameters()}\n",
    "    if log_likelihood:\n",
    "        likelihood_log = list()\n",
    "    # start runs\n",
    "    for iteration in range(random_restarts):\n",
    "    #for iteration in range(2):\n",
    "        # optimize and determine loss\n",
    "        # Perform a training for AIC and Laplace\n",
    "        model.train()\n",
    "        likelihood.train()\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "        for i in range(train_iterations):\n",
    "            # Zero gradients from previous iteration\n",
    "            optimizer.zero_grad()\n",
    "            # Output from model\n",
    "            output = model(X)\n",
    "            # Calc loss and backprop gradients\n",
    "            loss = -mll(output, Y)\n",
    "            if MAP:\n",
    "                log_p = log_prior(model)\n",
    "                loss -= log_p\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if log_param_path:\n",
    "                for param_name in model.named_parameters():\n",
    "                    param_log_dict[param_name[0]].append(param_name[1][0].item())\n",
    "            if log_likelihood:\n",
    "                likelihood_log.append(loss.item())\n",
    "\n",
    "        if with_BFGS:\n",
    "            # Additional BFGS optimization to better ensure optimal parameters\n",
    "            # LBFGS_optimizer = torch.optim.LBFGS(model.parameters(), max_iter=50, line_search_fn='strong_wolfe')\n",
    "            LBFGS_optimizer = torch.optim.LBFGS(\n",
    "                model.parameters(), max_iter=50,\n",
    "                line_search_fn='strong_wolfe')\n",
    "            # define closure\n",
    "\n",
    "            def closure():\n",
    "                LBFGS_optimizer.zero_grad()\n",
    "                output = model(X)\n",
    "                loss = -mll(output, Y)\n",
    "                if MAP:\n",
    "                    log_p = log_prior(model)\n",
    "                    loss -= log_p\n",
    "                LBFGS_optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                if log_param_path:\n",
    "                    for param_name in model.named_parameters():\n",
    "                        param_log_dict[param_name[0]].append(param_name[1][0].item())\n",
    "                if log_likelihood:\n",
    "                    likelihood_log.append(loss.item())\n",
    "                return loss\n",
    "            LBFGS_optimizer.step(closure)\n",
    "\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = model(X)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, Y)\n",
    "        if MAP:\n",
    "            log_p = log_prior(model)\n",
    "            loss -= log_p\n",
    "\n",
    "#        model.train_model(with_BFGS=with_BFGS)\n",
    "        current_loss = loss\n",
    "        # check if the current run is better than previous runs\n",
    "        if current_loss < best_loss:\n",
    "            # if it is the best, save all used parameters\n",
    "            best_loss = current_loss\n",
    "            for param_name, param in model.named_parameters():\n",
    "                optimal_parameters[param_name] = copy.deepcopy(param)\n",
    "\n",
    "        # set new random inital values\n",
    "        model.likelihood.noise_covar.noise = torch.rand(1) * (limits[\"Noise\"][1] - limits[\"Noise\"][0]) + limits[\"Noise\"][0]\n",
    "        #self.mean_module.constant = torch.rand(1) * (limits[\"Mean\"][1] - limits[\"Mean\"][0]) + limits[\"Mean\"][0]\n",
    "        for kernel in get_kernels_in_kernel_expression(model.covar_module):\n",
    "            hypers = limits[kernel._get_name()]\n",
    "            for hyperparameter in hypers:\n",
    "                new_value = torch.rand(1) * (hypers[hyperparameter][1] - hypers[hyperparameter][0]) + hypers[hyperparameter][0]\n",
    "                setattr(kernel, hyperparameter, new_value)\n",
    "\n",
    "        # print output if enabled\n",
    "        if options[\"training\"][\"print_optimizing_output\"]:\n",
    "            print(f\"HYPERPARAMETER OPTIMIZATION: Random Restart {iteration}: loss: {current_loss}, optimal loss: {best_loss}\")\n",
    "\n",
    "    # finally, set the hyperparameters those in the optimal run\n",
    "    model.initialize(**optimal_parameters)\n",
    "    output = model(X)\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "    loss = -mll(output, Y)\n",
    "    if MAP:\n",
    "        log_p = log_prior(model)\n",
    "        loss -= log_p\n",
    "    if not loss == best_loss:\n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "        print(loss)\n",
    "        print(best_loss)\n",
    "    if log_param_path:\n",
    "        logables = {\"training_log\": param_log_dict, \"likelihood_log\": likelihood_log}\n",
    "        return loss, logables\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-diddling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "END = 1\n",
    "COUNT = 5 \n",
    "train_x = torch.linspace(0, END, COUNT)\n",
    "train_y = torch.linspace(0, END, COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplest GP possible. SE with constant sigma_f \n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ZeroMean()\n",
    "        self.covar_module = gpytorch.kernels.RBFKernel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the MAP for 100 Iterations of ADAM and then 50 more of L-BFGS\n",
    "loss, training_log = optimize_hyperparameters(model, likelihood, 200, train_x, train_y, True, MAP=True, log_param_path=True, random_restarts=1, log_likelihood=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd04bad0940>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(training_log[\"training_log\"]['likelihood.noise_covar.raw_noise'])\n",
    "plt.plot(training_log[\"likelihood_log\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-1.2098, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " {'neg MLL': tensor(-1.7903, grad_fn=<NegBackward0>),\n",
       "  'punish term': tensor(-3.0001, dtype=torch.float64),\n",
       "  'punish without replacement': tensor(inf, dtype=torch.float64),\n",
       "  'laplace without replacement': tensor(inf, dtype=torch.float64, grad_fn=<SubBackward0>),\n",
       "  'num_replaced': tensor(3),\n",
       "  'parameter list': ['likelihood.noise_covar.raw_noise',\n",
       "   'covar_module.raw_outputscale',\n",
       "   'covar_module.base_kernel.raw_lengthscale'],\n",
       "  'parameter values': tensor([[-5.9927],\n",
       "          [-5.9931],\n",
       "          [ 0.0000]]),\n",
       "  'corrected Hessian': tensor([[ 4.6427e+01, -6.5769e-16,  0.0000e+00],\n",
       "          [ 1.1284e-15,  4.6427e+01,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  4.6427e+01]], dtype=torch.float64),\n",
       "  'diag(constructed eigvals)': tensor([46.4268, 46.4268, 46.4268], dtype=torch.float64),\n",
       "  'original symmetrized Hessian': tensor([[ 0.0639, -0.0540,  0.0000],\n",
       "          [-0.0540,  0.0559,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64),\n",
       "  'prior mean': tensor([[-3.5164],\n",
       "          [-1.6253],\n",
       "          [-0.2122]], dtype=torch.float64),\n",
       "  'diag(prior var)': tensor([12.8388,  5.0941,  3.5704], dtype=torch.float64),\n",
       "  'likelihood approximation': tensor(-1.2098, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       "  'Derivative time': 0.001775503158569336,\n",
       "  'Approximation time': 0.0004525184631347656,\n",
       "  'Correction time': 0.00020241737365722656,\n",
       "  'Prior generation time': 0.0001373291015625,\n",
       "  'Total time': 0.002559185028076172})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(train_x)\n",
    "loss = -mll(output, train_x)\n",
    "metrics.calculate_laplace(model, -loss, with_prior=True, param_punish_term=-1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/besginow/anaconda3/envs/sage/lib/python3.10/site-packages/gpytorch/models/exact_gp.py:274: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    output = model(train_x)\n",
    "    observed_pred = likelihood(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0034, 0.0009],\n",
       "        [0.0009, 0.0034]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_pred.covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0658, 0.0658])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_pred.loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Messages from stanc:\n",
      "Warning in '/tmp/httpstan_njirf1m1/model_mo3nc6ll.stan', line 5, column 12: A\n",
      "    control flow statement inside function softplus depends on argument v. At\n",
      "    '/tmp/httpstan_njirf1m1/model_mo3nc6ll.stan', line 32, column 74 to\n",
      "    column 82, the value of v depends on parameter(s): theta.\n",
      "Warning in '/tmp/httpstan_njirf1m1/model_mo3nc6ll.stan', line 5, column 12: A\n",
      "    control flow statement inside function softplus depends on argument v. At\n",
      "    '/tmp/httpstan_njirf1m1/model_mo3nc6ll.stan', line 32, column 51 to\n",
      "    column 59, the value of v depends on parameter(s): theta.\n",
      "Warning in '/tmp/httpstan_njirf1m1/model_mo3nc6ll.stan', line 5, column 12: A\n",
      "    control flow statement inside function softplus depends on argument v. At\n",
      "    '/tmp/httpstan_njirf1m1/model_mo3nc6ll.stan', line 32, column 120 to\n",
      "    column 128, the value of v depends on parameter(s): theta.\n",
      "Warning: The parameter theta has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Sampling:   0%\n",
      "Sampling: 100% (2000/2000)\n",
      "Sampling: 100% (2000/2000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 2.2e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: multi_normal_lpdf: Covariance matrix is not symmetric. Covariance matrix[1,2] = inf, but Covariance matrix[2,1] = inf (in '/tmp/httpstan_nkkkdkya/model_mo3nc6ll.stan', line 34, column 8 to column 32)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: multi_normal_lpdf: Covariance matrix is not symmetric. Covariance matrix[1,2] = -nan, but Covariance matrix[2,1] = -nan (in '/tmp/httpstan_nkkkdkya/model_mo3nc6ll.stan', line 34, column 8 to column 32)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: multi_normal_lpdf: Covariance matrix is not symmetric. Covariance matrix[1,2] = inf, but Covariance matrix[2,1] = inf (in '/tmp/httpstan_nkkkdkya/model_mo3nc6ll.stan', line 34, column 8 to column 32)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: multi_normal_lpdf: Covariance matrix is not symmetric. Covariance matrix[1,2] = inf, but Covariance matrix[2,1] = inf (in '/tmp/httpstan_nkkkdkya/model_mo3nc6ll.stan', line 34, column 8 to column 32)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: multi_normal_lpdf: Covariance matrix is not symmetric. Covariance matrix[1,2] = -nan, but Covariance matrix[2,1] = -nan (in '/tmp/httpstan_nkkkdkya/model_mo3nc6ll.stan', line 34, column 8 to column 32)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: multi_normal_lpdf: Covariance matrix is not symmetric. Covariance matrix[1,2] = -nan, but Covariance matrix[2,1] = -nan (in '/tmp/httpstan_nkkkdkya/model_mo3nc6ll.stan', line 34, column 8 to column 32)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "/home/besginow/anaconda3/envs/sage/lib/python3.10/site-packages/gpytorch/models/exact_gp.py:274: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1185.0641)\n",
      "{'Kernel code': '\\n    functions {\\n        array[] real softplus(array[] real v){\\n            array[num_elements(v)] real r;\\n            for (d in 1:num_elements(v)){\\n                r[d] = log(1.0 + exp(v[d]));\\n            }\\n            return r;\\n        }\\n        real softplus(real v){\\n            return log(1.0 + exp(v));\\n        }\\n    }\\n    \\n    data {\\n        int N;\\n        int D;\\n        array[N] real x;\\n        vector[N] y;\\n        vector[D] t_mu;\\n        matrix[D, D] t_sigma;\\n    }\\n    \\n    parameters {\\n        vector<lower=-3.0>[D] theta;\\n    }\\n    \\n    model {\\n        matrix[N, N] K;\\n        vector[N] mu;\\n        theta ~ multi_normal(t_mu, t_sigma);\\n        K = (identity_matrix(dims(x)[1]).*softplus(theta[1])) + (softplus(theta[2]) .* gp_exp_quad_cov(x, 1.0, softplus(theta[3])));\\n        mu = zeros_vector(N);\\n        y ~ multi_normal(mu, K);\\n    }\\n    ', 'seed': 336947, 'Likelihood time': 1.7930924892425537, 'Model compile time': 0.11720156669616699, 'Sampling time': 0.81217360496521, 'Total time': 4.99091911315918, 'Bad entries': 0, 'Parameter statistics': {'theta.1': {'mu': -1.698602763614497, 'var': 1.6008702873414664}, 'theta.2': {'mu': -1.2287886063814633, 'var': 1.7155257820189904}, 'theta.3': {'mu': -0.0023142617869117217, 'var': 2.555815162338632}}, 'Parameter prior': {'mu': tensor([[-3.5164],\n",
      "        [-1.6253],\n",
      "        [-0.2122]]), 'var': tensor([[12.8388,  0.0000,  0.0000],\n",
      "        [ 0.0000,  5.0941,  0.0000],\n",
      "        [ 0.0000,  0.0000,  3.5704]])}, 'likelihood approximation': tensor(-1185.0641)}\n"
     ]
    }
   ],
   "source": [
    "from metrics import calculate_mc_STAN\n",
    "# Perform MCMC\n",
    "MCMC_approx, MC_log = calculate_mc_STAN(\n",
    "    model, likelihood, 1000)\n",
    "MC_logs = dict()\n",
    "print(MCMC_approx)\n",
    "print(MC_log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
